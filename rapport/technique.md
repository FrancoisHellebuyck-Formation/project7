# Rapport technique ‚Äì Assistant intelligent de recommandation d‚Äô√©v√©nements culturels

## 1. Objectifs du projet
### Contexte : 

- Puls-Events est une entreprise technologique innovante sp√©cialis√©e dans le d√©veloppement d'une plateforme de recommandations culturelles personnalis√©es.

- Pour am√©liorer l'exp√©rience utilisateur et r√©pondre √† l'√©volution des attentes num√©riques, Puls-Events souhaite int√©grer un assistant intelligent capable de g√©rer les requ√™tes des utilisateurs en temps r√©el.

### Probl√©matique :

- Un syst√®me RAG (Retrieval-Augmented Generation) r√©pond aux besoins m√©tier de Puls-Events en r√©solvant la probl√©matique centrale de l'acc√®s pr√©cis et fiable √† l'information √©v√©nementielle par un chatbot.

- Le RAG surmonte les limites des mod√®les de langage classiques (LLMs) pour fournir une solution √† la fois performante et √©conomiquement viable.

### Objectif du POC :

- L'objectif du POC pour Puls-Events est de d√©montrer de mani√®re concr√®te et mesurable que la technologie RAG (Retrieval-Augmented Generation), en utilisant LangChain, Mistral et FAISS, est la solution optimale pour alimenter le futur chatbot d'√©v√©nements culturels.

- Cet objectif se d√©cline en trois axes principaux : 
    - la faisabilit√© technique, 
    - la valeur m√©tier 
    - et la performance.

1. D√©montrer la Faisabilit√© Technique üõ†Ô∏è

Il s'agit de prouver que l'int√©gration des composants cl√©s est fonctionnelle et stable, menant √† une solution pr√™te pour l'industrialisation.

Int√©gration du Pipeline Complet : Prouver la capacit√© √† orchestrer le flux de donn√©es de bout en bout : de l'extraction des donn√©es d'√©v√©nements r√©cents via l'API Open Agenda, √† leur transformation en embeddings, leur stockage dans l'index FAISS, et leur utilisation par le LLM Mistral via LangChain pour la g√©n√©ration de la r√©ponse.

Portabilit√© et D√©ploiement : Valider la capacit√© √† livrer un syst√®me standardis√© et reproductible gr√¢ce √† la conteneurisation Docker et √† l'exposition via une API REST (FastAPI).

2. D√©montrer la Valeur M√©tier (Pertinence) ‚ú®

L'objectif est de s'assurer que le syst√®me r√©pond directement aux besoins de l'utilisateur final et de l'entreprise Puls-Events.

V√©racit√© des R√©ponses : D√©montrer que le RAG √©limine les "hallucinations" en basant syst√©matiquement les r√©ponses sur le contexte factuel et √† jour des √©v√©nements (dates, lieux, artistes, genres) extrait d'Open Agenda. C'est la validation de la fiabilit√© de l'information.

Exp√©rience Utilisateur Am√©lior√©e : Prouver que le chatbot peut g√©rer et r√©pondre avec fluidit√© √† une grande vari√©t√© de questions en langage naturel, y compris les requ√™tes s√©mantiques complexes (e.g., "Je cherche quelque chose de familial le week-end prochain") bas√©es sur le jeu de test annot√©.

Efficacit√© Op√©rationnelle : Montrer que ce syst√®me est plus rentable et plus rapide √† actualiser qu'une approche de fine-tuning du LLM, car seule la base vectorielle a besoin d'√™tre mise √† jour avec les nouveaux √©v√©nements.

3. D√©montrer la Performance (Qualit√© et Rapidit√©) ‚ö°

Il faut quantifier l'efficacit√© du syst√®me √† la fois sur la recherche et la g√©n√©ration.

Performance du Retrieval : Mesurer l'efficacit√© de FAISS √† remonter les fragments de texte pertinents. Le Hit Rate (pourcentage de fois o√π le bon fragment est dans les top-k r√©sultats) est la m√©trique cl√© pour valider que la bonne information est trouv√©e.

Qualit√© de la G√©n√©ration : Mesurer la fid√©lit√© (faithfulness) et la pertinence de la r√©ponse g√©n√©r√©e par Mistral par rapport au contexte fourni. La r√©ponse doit √™tre bien r√©dig√©e, concise et r√©pondre directement √† la question de l'utilisateur.

Latence (Temps de R√©ponse) : S'assurer que le syst√®me complet (API + RAG) offre un temps de r√©ponse acceptable pour une exp√©rience utilisateur fluide (cible typique : quelques secondes ou moins).


- P√©rim√®tre : Zone g√©ographique cibl√©e, p√©riode d‚Äô√©v√©nements, donn√©es utilis√©es.

## Architecture du syst√®me
Sch√©ma global (sch√©ma UML) :
Donn√©es entrantes (API Open Agenda)
Pr√©traitement / embeddings / base vectorielle
Int√©gration LLM avec LangChain
Exposition via API
Technologies utilis√©es :


3. Pr√©paration et vectorisation des donn√©es
Source de donn√©es : API Open Agenda (param√®tres utilis√©s, filtres appliqu√©s)
Nettoyage : Exemples d‚Äôanomalies corrig√©es, m√©thodes utilis√©es
Chunking : Raison du d√©coupage, taille choisie
Embedding :
Mod√®le utilis√© (ex. : Mistral embedding API)
Dimensionnalit√©, logique de batch, format des vecteurs

4. Choix du mod√®le NLP
Mod√®le s√©lectionn√© :
Pourquoi ce mod√®le ? (Crit√®res : co√ªt, qualit√©, compatibilit√© LangChain‚Ä¶)
Prompting (si utilis√©) : Prompt de base / structure
Limites du mod√®le : 

5. Construction de la base vectorielle
Faiss utilis√© :
Strat√©gie de persistance : 
Format de sauvegarde ?
nommage ?
M√©tadonn√©es associ√©es : 
Ce qui est conserv√© pour chaque document

6. API et endpoints expos√©s
Framework utilis√© : FastAPI / Flask
Endpoints cl√©s :
/ask : question utilisateur, r√©ponse du syst√®me
/rebuild : reconstruction de l‚Äôindex (si besoin)
Format des requ√™tes/r√©ponses
Exemple d‚Äôappel API : avec curl ou code Python
Tests effectu√©s et document√©s
Gestion des erreurs / limitations

7. √âvaluation du syst√®me
Jeu de test annot√© :
Nombre d‚Äôexemples
M√©thode d‚Äôannotation
M√©triques d‚Äô√©valuation :
Exemple : similarit√© s√©mantique, taux de couverture des r√©ponses, score de satisfaction (subjectif)
R√©sultats obtenus :
Analyse quantitative (scores globaux)
Analyse qualitative (exemples de bonnes/mauvaises r√©ponses)
8. Recommandations et perspectives
Ce qui fonctionne bien
Limites du POC :
Volum√©trie, performance, co√ªt, couverture th√©matique ?
Am√©liorations possibles :
Ajout de‚Ä¶Am√©lioration de..
Passage en production via‚Ä¶

9.  Organisation du d√©p√¥t GitHub
Arborescence du d√©p√¥t (fichiers cl√©s, scripts, dossiers)
Explication rapide de chaque r√©pertoire

10. Annexes (exemples)
Extraits du jeu de test annot√©
Prompt utilis√© (si sp√©cifique)
Extraits de logs ou exemples de r√©ponse JSON
