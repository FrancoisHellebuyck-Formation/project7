# Rapport technique ‚Äì Assistant intelligent de recommandation d‚Äô√©v√©nements culturels

## 1. Objectifs du projet
### Contexte : 

- Puls-Events est une entreprise technologique innovante sp√©cialis√©e dans le d√©veloppement d'une plateforme de recommandations culturelles personnalis√©es.

- Pour am√©liorer l'exp√©rience utilisateur et r√©pondre √† l'√©volution des attentes num√©riques, Puls-Events souhaite int√©grer un assistant intelligent capable de g√©rer les requ√™tes des utilisateurs en temps r√©el.

### Probl√©matique :

- Un syst√®me RAG (Retrieval-Augmented Generation) r√©pond aux besoins m√©tier de Puls-Events en r√©solvant la probl√©matique centrale de l'acc√®s pr√©cis et fiable √† l'information √©v√©nementielle par un chatbot.

- Le RAG surmonte les limites des mod√®les de langage classiques (LLMs) pour fournir une solution √† la fois performante et √©conomiquement viable.

### Objectif du POC :

- L'objectif du POC pour Puls-Events est de d√©montrer de mani√®re concr√®te et mesurable que la technologie RAG (Retrieval-Augmented Generation), en utilisant LangChain, Mistral et FAISS, est la solution optimale pour alimenter le futur chatbot d'√©v√©nements culturels.

- Cet objectif se d√©cline en trois axes principaux : 
    - la faisabilit√© technique, 
    - la valeur m√©tier 
    - et la performance.

1. D√©montrer la Faisabilit√© Technique üõ†Ô∏è

Il s'agit de prouver que l'int√©gration des composants cl√©s est fonctionnelle et stable, menant √† une solution pr√™te pour l'industrialisation.

Int√©gration du Pipeline Complet : Prouver la capacit√© √† orchestrer le flux de donn√©es de bout en bout : de l'extraction des donn√©es d'√©v√©nements r√©cents via l'API Open Agenda, √† leur transformation en embeddings, leur stockage dans l'index FAISS, et leur utilisation par le LLM Mistral via LangChain pour la g√©n√©ration de la r√©ponse.

Portabilit√© et D√©ploiement : Valider la capacit√© √† livrer un syst√®me standardis√© et reproductible gr√¢ce √† la conteneurisation Docker et √† l'exposition via une API REST (FastAPI).

2. D√©montrer la Valeur M√©tier (Pertinence) ‚ú®

L'objectif est de s'assurer que le syst√®me r√©pond directement aux besoins de l'utilisateur final et de l'entreprise Puls-Events.

V√©racit√© des R√©ponses : D√©montrer que le RAG √©limine les "hallucinations" en basant syst√©matiquement les r√©ponses sur le contexte factuel et √† jour des √©v√©nements (dates, lieux, artistes, genres) extrait d'Open Agenda. C'est la validation de la fiabilit√© de l'information.

Exp√©rience Utilisateur Am√©lior√©e : Prouver que le chatbot peut g√©rer et r√©pondre avec fluidit√© √† une grande vari√©t√© de questions en langage naturel, y compris les requ√™tes s√©mantiques complexes (e.g., "Je cherche quelque chose de familial le week-end prochain") bas√©es sur le jeu de test annot√©.

Efficacit√© Op√©rationnelle : Montrer que ce syst√®me est plus rentable et plus rapide √† actualiser qu'une approche de fine-tuning du LLM, car seule la base vectorielle a besoin d'√™tre mise √† jour avec les nouveaux √©v√©nements.

3. D√©montrer la Performance (Qualit√© et Rapidit√©) ‚ö°

Il faut quantifier l'efficacit√© du syst√®me √† la fois sur la recherche et la g√©n√©ration.

Performance du Retrieval : Mesurer l'efficacit√© de FAISS √† remonter les fragments de texte pertinents. Le Hit Rate (pourcentage de fois o√π le bon fragment est dans les top-k r√©sultats) est la m√©trique cl√© pour valider que la bonne information est trouv√©e.

Qualit√© de la G√©n√©ration : Mesurer la fid√©lit√© (faithfulness) et la pertinence de la r√©ponse g√©n√©r√©e par Mistral par rapport au contexte fourni. La r√©ponse doit √™tre bien r√©dig√©e, concise et r√©pondre directement √† la question de l'utilisateur.

Latence (Temps de R√©ponse) : S'assurer que le syst√®me complet (API + RAG) offre un temps de r√©ponse acceptable pour une exp√©rience utilisateur fluide (cible typique : quelques secondes ou moins).


- P√©rim√®tre : Zone g√©ographique cibl√©e, p√©riode d‚Äô√©v√©nements, donn√©es utilis√©es.

## Architecture du syst√®me
### Sch√©ma global :

![Sch√©ma d'architecture](./Architecture.png)

### Donn√©es entrantes (API Open Agenda)

**Source de donn√©es :** API Open Agenda v2 (https://api.openagenda.com/v2)

**Endpoints utilis√©s :**
- `/agendas` : R√©cup√©ration des agendas culturels officiels par r√©gion
- `/agendas/{uid}/events` : R√©cup√©ration des √©v√©nements pour chaque agenda

**Param√®tres de collecte :**
- **R√©gion cibl√©e** : Occitanie (configurable via `OA_REGION` dans .env)
- **Pagination** : Curseur `after[]` avec taille de page de 100 √©v√©nements (`OA_PAGE_SIZE=100`)
- **Filtrage temporel** :
  - Agendas : `updatedAt >= date` (derni√®re ex√©cution ou 1 an par d√©faut)
  - √âv√©nements : `createdAt >= date` OU `updatedAt >= date` (mode UPDATE)

**Donn√©es extraites par √©v√©nement :**
- **M√©tadonn√©es** : uid, title, description, slug
- **Temporalit√©** : timings (date_debut, date_fin), createdAt, updatedAt
- **Localisation** : location (coordinates, name, address, city, region)
- **Classification** : keywords, categories
- **Relations** : agendaUid (lien avec l'agenda parent)

**Stockage interm√©diaire :**
- **Base MongoDB** : Collections `agendas` et `events`
- **Strat√©gie upsert** : √âvite les doublons gr√¢ce √† des cl√©s uniques (uid pour agendas, (uid, agendaUid) pour events)
- **D√©doublonnement** : Script de nettoyage pour √©liminer les √©v√©nements dupliqu√©s par uid

**Mise √† jour incr√©mentale :**
- Pipeline de mise √† jour qui sauvegarde les collections existantes (`_update_YYYYMMDD_HHMMSS`)
- R√©cup√©ration s√©lective des agendas/√©v√©nements modifi√©s depuis la derni√®re ex√©cution
- Tracking des ex√©cutions dans la collection `last_update` avec m√©tadonn√©es compl√®tes

### Pr√©traitement / embeddings / base vectorielle

**Pipeline de traitement (src/chunks/chunks_document.py) :**

1. **Formatage des documents**
   - Conversion des √©v√©nements MongoDB en texte structur√©
   - Format : `Titre: {title}\nDates: {date_debut} - {date_fin}\nDescription: {description}\nLieu: {locationName}\nMots-cl√©s: {keywords}`

2. **Extraction des m√©tadonn√©es**
   - Champs conserv√©s : event_id, title, city, date_debut, date_fin, location (coordonn√©es GPS), region, keywords

3. **Chunking (LangChain RecursiveCharacterTextSplitter)**
   - **Taille des chunks** : 500 caract√®res (configurable via `CHUNK_SIZE`)
   - **Overlap** : 100 caract√®res (configurable via `CHUNK_OVERLAP`)
   - **Raison** : √âquilibre entre contexte suffisant et pr√©cision de la recherche
   - **Sortie** : Objets LangChain `Document` avec contenu + m√©tadonn√©es

**G√©n√©ration des embeddings (src/embeddings/embeddings.py) :**

- **Mod√®le** : `intfloat/multilingual-e5-large` (HuggingFace Transformers)
- **Dimensionnalit√©** : 1024 dimensions
- **Multilingue** : Support de 100+ langues incluant le fran√ßais
- **Local** : Pas d'API externe, inf√©rence locale (pas de cl√© API requise)
- **Strat√©gie** :
  - Average pooling avec masque d'attention
  - Pr√©fixes : "passage:" pour documents, "query:" pour requ√™tes
  - Normalisation L2 pour similarit√© cosinus optimale
- **Performance** :
  - D√©tection automatique du device (CUDA, MPS, CPU)
  - Batch processing (taille de batch configurable, d√©faut : 32)
  - ~50-100 chunks/seconde sur Apple Silicon (MPS)

**Construction de la base vectorielle (src/vectors/vectors.py) :**

- **Biblioth√®que** : FAISS (Facebook AI Similarity Search)
- **Type d'index** : FAISS avec LangChain wrapper
- **Persistance** :
  - Format : Fichiers binaires FAISS + pickle pour m√©tadonn√©es
  - Chemin : `data/faiss_index/` (configurable via `FAISS_INDEX_PATH`)
  - Sauvegarde : `index.faiss` + `index.pkl`
- **M√©tadonn√©es stock√©es** : Toutes les m√©tadonn√©es extraites sont conserv√©es avec chaque vecteur
- **Op√©rations support√©es** :
  - Cr√©ation d'index
  - Chargement d'index existant
  - Ajout de documents
  - Recherche par similarit√© (similarity_search_with_score)
  - Suppression d'index
  - Statistiques (nombre de vecteurs, dimension)

**Statistiques actuelles :**
- ~28,962 vecteurs index√©s (exemple du d√©veloppement)
- Dimension : 1024
- Couvre tous les √©v√©nements culturels d'Occitanie r√©cents

### Int√©gration LLM avec LangChain

**Mod√®le LLM s√©lectionn√© :**
- **Fournisseur** : Mistral AI
- **Mod√®le** : `mistral-small-latest` (configurable via `MISTRAL_MODEL`)
- **Raisons du choix** :
  - Excellence sur le fran√ßais
  - Rapport qualit√©/co√ªt optimal
  - Latence faible
  - Compatibilit√© native avec LangChain
  - API simple et fiable

**Architecture RAG (Retrieval-Augmented Generation) :**

1. **Recherche s√©mantique (Retrieval)**
   - Query embedding avec le m√™me mod√®le E5
   - Recherche FAISS des top-k documents similaires (k=5 par d√©faut)
   - R√©cup√©ration du contenu + m√©tadonn√©es + scores de similarit√©

2. **Enrichissement du contexte**
   - Formatage des documents r√©cup√©r√©s en contexte structur√©
   - Inclusion des m√©tadonn√©es pertinentes (titre, lieu, dates)
   - Limitation du contexte pour √©viter le d√©passement de tokens

3. **G√©n√©ration de r√©ponse**
   - **Prompt syst√®me** : Charg√© depuis `src/chat/ps.md` (Puls-Events persona)
   - **Directives** :
     - R√©ponses bas√©es uniquement sur le contexte fourni
     - Champ d'application : Occitanie et √©v√©nements culturels
     - Ton : Enthousiaste, accueillant, clair et concis
     - Gestion de l'ambigu√Øt√© et des questions hors-sujet
   - **Prompt utilisateur enrichi** : Question + contexte RAG
   - **Appel Mistral AI** : Via `mistral_client.chat.complete()`
   - **Retour** : R√©ponse + contexte utilis√© + statistiques tokens

**Impl√©mentation LangChain :**
- **Custom Embeddings** : Classe `E5Embeddings(Embeddings)` compatible LangChain
- **Vector Store** : Wrapper FAISS de LangChain
- **Retrieval** : `vector_store.similarity_search_with_score(query, k=k)`
- **Messages** : `SystemMessage` + `UserMessage` pour Mistral AI

**Gestion de la qualit√© :**
- Syst√®me de scoring de similarit√© pour filtrer les r√©sultats peu pertinents
- Limitation du nombre de documents contextuels (√©vite la surcharge)
- Tracking des tokens utilis√©s (prompt + completion + total)
- Fallback gracieux si pas de contexte pertinent trouv√©

### Exposition via API

**Framework** : FastAPI 0.120.1+

**Architecture de l'API (src/api/main.py) :**

**Endpoints principaux :**

1. **GET /** - Point d'entr√©e
   - Liste tous les endpoints disponibles
   - Version de l'API

2. **GET /health** - Health check
   - Statut : ok | degraded
   - √âtat des composants : vector_store, embeddings_model, mistral_client
   - Permet le monitoring

3. **GET /stats** - Statistiques du vector store
   - Nombre de vecteurs index√©s
   - Dimension des vecteurs
   - Chemin de l'index

4. **POST /search** - Recherche s√©mantique pure
   - **Entr√©e** : `{"query": "...", "k": 5}`
   - **Sortie** : R√©sultats avec scores, titres, contenus, m√©tadonn√©es
   - **Validation** : query non vide, k entre 1 et 100

5. **POST /ask** - Question-r√©ponse avec RAG + Mistral AI
   - **Entr√©e** : `{"question": "...", "k": 5, "system_prompt": "..." (optionnel)}`
   - **Processus** :
     1. Recherche s√©mantique (top-k documents)
     2. Enrichissement du prompt avec contexte
     3. Appel Mistral AI
     4. Retour de la r√©ponse
   - **Sortie** : `{"question": "...", "answer": "...", "context_used": [...], "tokens_used": {...}}`

6. **POST /rebuild** - Reconstruction incr√©mentale de l'index FAISS
   - Lance `update_pipeline.py` en arri√®re-plan
   - V√©rification pr√©alable : nouveaux √©v√©nements pr√©sents ?
   - **Workflow** :
     1. R√©cup√®re la date de derni√®re ex√©cution
     2. Compte les nouveaux √©v√©nements MongoDB
     3. Si aucun : annule avec statut "warning"
     4. Sinon : lance le pipeline complet
     5. Recharge automatiquement l'index en m√©moire
   - **Statuts** : started | running | success | success_with_warning | warning | error
   - Protection anti-concurrence (un seul rebuild √† la fois)

7. **GET /rebuild/status** - Suivi du rebuild
   - Statut actuel et d√©tails
   - Date de derni√®re mise √† jour
   - Timestamps de d√©marrage

**Fonctionnalit√©s techniques :**

- **CORS** : Configur√© pour autoriser les requ√™tes cross-origin
- **Startup event** : Chargement automatique du vector store + embeddings + Mistral client au d√©marrage
- **Background tasks** : Ex√©cution asynchrone du rebuild sans bloquer l'API
- **Rechargement automatique** : Nouvel index FAISS charg√© en m√©moire apr√®s rebuild r√©ussi
- **Auto-documentation** : Swagger UI accessible √† `/docs`
- **Gestion d'erreurs** : HTTPException avec codes appropri√©s (422, 503, 500)
- **Logging** : Logs d√©taill√©s de toutes les op√©rations
- **Hot-reload** : Activ√© en mode d√©veloppement

**Format des r√©ponses :**
- JSON structur√© avec mod√®les Pydantic (validation automatique)
- Codes HTTP standards
- Messages d'erreur explicites

**D√©ploiement :**
- **D√©veloppement** : `uvicorn` avec hot-reload (`make run-api`)
- **Production** : Docker + docker-compose
- **Port** : 8000 (configurable)
- **Host** : 0.0.0.0

**Tests unitaires :**
- 10 tests passants couvrant tous les endpoints principaux
- Mocking complet des d√©pendances (MongoDB, FAISS, Mistral)
- Pytest avec support async
- Commandes : `make test` | `make test-cov`

### Technologies utilis√©es :

**Backend et orchestration :**
- **Python 3.13+** : Langage principal
- **FastAPI 0.120.1+** : Framework web moderne et rapide
- **Uvicorn** : Serveur ASGI avec hot-reload
- **LangChain 1.0.2+** : Framework d'orchestration LLM
  - `langchain-community` : Int√©grations communautaires
  - `langchain-mistralai` : Connecteur Mistral AI
  - `langchain-text-splitters` : Chunking de documents
- **python-dotenv** : Gestion des variables d'environnement

**LLM et embeddings :**
- **Mistral AI API (mistralai 1.9.11+)** : G√©n√©ration de r√©ponses
  - Mod√®le : `mistral-small-latest`
  - SystemMessage/UserMessage pour le chat
- **HuggingFace Transformers 4.57.1+** : Mod√®les NLP locaux
  - `intfloat/multilingual-e5-large` : Embeddings multilingues (1024 dim)
- **PyTorch 2.9.0+** : Backend pour les transformers
  - Support CUDA/MPS/CPU

**Base de donn√©es et vectorielle :**
- **MongoDB (PyMongo 4.15.3+ / Motor 3.7.1+)** : Stockage des √©v√©nements
  - Collections : `agendas`, `events`, `last_update`
  - Op√©rations bulk avec upsert
- **FAISS (faiss-cpu 1.12.0+)** : Recherche vectorielle
  - Index persistant sur disque
  - Recherche par similarit√© cosinus

**Scraping et API :**
- **Requests 2.32.5+** : Appels HTTP vers Open Agenda API
- **BeautifulSoup4 (bs4 0.0.2+)** : Parsing HTML si n√©cessaire

**Validation et mod√®les de donn√©es :**
- **Pydantic 2.12.3+** : Validation des donn√©es API
  - Mod√®les pour requ√™tes/r√©ponses FastAPI

**Outils de d√©veloppement :**
- **pytest 8.3.0+** : Tests unitaires
  - `pytest-asyncio 0.24.0+` : Support async
  - `pytest-cov 6.0.0+` : Couverture de code
  - `httpx 0.28.0+` : Client HTTP async pour tests
- **flake8 7.3.0+** : Linter Python
- **uv** : Gestionnaire de d√©pendances rapide
- **Make** : Orchestration des commandes

**Conteneurisation et d√©ploiement :**
- **Docker** : Conteneurisation de l'application
- **docker-compose** : Orchestration multi-conteneurs
  - Service MongoDB
  - Service API FastAPI

**Utilitaires :**
- **NumPy 2.3.4+** : Calculs matriciels
- **pathlib** : Manipulation de chemins
- **asyncio** : Programmation asynchrone
- **logging** : Journalisation applicative

**Configuration syst√®me :**
- **macOS fix** : `KMP_DUPLICATE_LIB_OK=TRUE` pour OpenMP
- **Environnement** : Fichier `.env` pour la configuration
- **Makefile** : Commandes standardis√©es (`make install`, `make run-all`, etc.)


### Pr√©paration et vectorisation des donn√©es
#### Source de donn√©es : API Open Agenda (param√®tres utilis√©s, filtres appliqu√©s)
- **Endpoints** : `/agendas` pour lister les agendas officiels, puis `/agendas/{uid}/events` pour r√©cup√©rer les √©v√©nements.
- **Param√®tres cl√©s** : `official: 1` pour ne retenir que les sources fiables, `search: Occitanie` pour le ciblage g√©ographique.
- **Filtres temporels** : Le pipeline de mise √† jour incr√©mentale (`update`) filtre les agendas et √©v√©nements sur la base de la date de la derni√®re ex√©cution (`createdAt >= date` ou `updatedAt >= date`), assurant une collecte efficace des nouveaut√©s.

#### Nettoyage : Exemples d‚Äôanomalies corrig√©es, m√©thodes utilis√©es
- **Anomalie corrig√©e** : Pr√©sence d'√©v√©nements en double, identifi√©s par un `uid` identique mais des `_id` MongoDB diff√©rents.
- **M√©thode utilis√©e** : Le script `src/corpus/deduplicate_events.py` est ex√©cut√© apr√®s la collecte. Pour chaque `uid` dupliqu√©, il conserve uniquement l'√©v√©nement le plus r√©cent en se basant sur le champ `updatedAt` et supprime les autres.

#### Chunking : Raison du d√©coupage, taille choisie
- **Outil** : `RecursiveCharacterTextSplitter` de LangChain.
- **Taille choisie** : **500 caract√®res** (`CHUNK_SIZE`) avec un chevauchement de **100 caract√®res** (`CHUNK_OVERLAP`).
- **Raison du d√©coupage** : Cette configuration offre un √©quilibre optimal. Les chunks sont assez petits pour que la recherche s√©mantique soit tr√®s pr√©cise, mais assez grands pour conserver un contexte s√©mantique suffisant. Le chevauchement emp√™che de couper des phrases ou des id√©es importantes entre deux chunks.

#### Embedding :
##### Mod√®le utilis√© (ex. : Mistral embedding API)
- **Mod√®le** : `intfloat/multilingual-e5-large`, un mod√®le de pointe ex√©cut√© localement via la biblioth√®que HuggingFace Transformers.
- **Justification** : Ce choix a √©t√© fait pour ses excellentes performances sur les t√¢ches de *retrieval* en fran√ßais, sa capacit√© √† s'ex√©cuter localement (pas de d√©pendance √† une API externe, pas de co√ªt par token) et sa dimensionnalit√© √©lev√©e.

##### Dimensionnalit√©, logique de batch, format des vecteurs
- **Dimensionnalit√©** : **1024 dimensions**, ce qui permet une repr√©sentation s√©mantique tr√®s riche.
- **Logique de batch** : La vectorisation est effectu√©e par lots (taille de 32 par d√©faut) pour optimiser l'utilisation des ressources mat√©rielles (CPU/GPU/MPS) et acc√©l√©rer le traitement.
- **Format des vecteurs** : Les vecteurs sont des flottants normalis√©s (L2), ce qui est id√©al pour les calculs de similarit√© cosinus. Le mod√®le utilise des pr√©fixes sp√©cifiques (`"passage:"` pour les documents, `"query:"` pour les requ√™tes) afin d'am√©liorer la pertinence de la recherche.

### Choix du mod√®le NLP
##### Mod√®le s√©lectionn√© :
- **Fournisseur** : Mistral AI
- **Mod√®le** : `mistral-small-latest` (configurable via la variable d'environnement `MISTRAL_MODEL`)

##### Pourquoi ce mod√®le ? (Crit√®res : co√ªt, qualit√©, compatibilit√© LangChain‚Ä¶)
- **Qualit√© sur le fran√ßais** : Les mod√®les Mistral sont reconnus pour leur excellente performance et leur compr√©hension nuanc√©e de la langue fran√ßaise.
- **Rapport performance/co√ªt** : `mistral-small-latest` offre un excellent √©quilibre entre une latence faible, une haute qualit√© de g√©n√©ration et un co√ªt par token ma√Ætris√©, ce qui est id√©al pour un POC.
- **Compatibilit√© LangChain** : Le mod√®le est nativement support√© via le package `langchain-mistralai`, permettant une int√©gration simple et rapide dans l'architecture RAG.

##### Prompting (si utilis√©) : Prompt de base / structure
- **Prompt Syst√®me** : Un prompt syst√®me d√©taill√©, stock√© dans `src/chat/ps.md`, d√©finit la personnalit√© du chatbot ("Puls-Events"). Il lui donne des instructions strictes : r√©pondre uniquement sur la base du contexte fourni, se limiter √† la r√©gion Occitanie, et adopter un ton convivial et pr√©cis.
- **Structure du prompt enrichi** : La requ√™te finale envoy√©e √† Mistral est structur√©e en deux parties :
    1.  `SystemMessage` : Contient les instructions de `ps.md`.
    2.  `UserMessage` : Contient un prompt enrichi qui combine :
        - Le contexte r√©cup√©r√© depuis la base vectorielle (les √©v√©nements pertinents).
        - La question originale de l'utilisateur.
        - Une instruction finale demandant de baser la r√©ponse sur le contexte.

##### Limites du mod√®le :
- **D√©pendance √† une API externe** : Contrairement au mod√®le d'embedding, l'utilisation de Mistral AI n√©cessite une connexion internet et une cl√© API valide, ce qui engendre un co√ªt par utilisation (bas√© sur les tokens).
- **Fen√™tre de contexte** : Le mod√®le a une taille de contexte limit√©e. Le nombre de documents inject√©s dans le prompt (`RAG_TOP_K`) doit √™tre contr√¥l√© pour ne pas d√©passer cette limite et pour ma√Ætriser les co√ªts.

### Construction de la base vectorielle
##### Faiss utilis√© :
- **Biblioth√®que** : **FAISS** (Facebook AI Similarity Search), une biblioth√®que hautement optimis√©e pour la recherche de similarit√© sur de grands volumes de vecteurs.
- **Int√©gration** : Le projet utilise le wrapper `FAISS` fourni par `langchain-community`, ce qui simplifie la cr√©ation, la sauvegarde, le chargement et l'interrogation de l'index.

##### Strat√©gie de persistance :
- **Format de sauvegarde** : L'index est sauvegard√© sur le disque dans le r√©pertoire `data/faiss_index/` (configurable via `FAISS_INDEX_PATH`). Il se compose de deux fichiers :
    - `index.faiss` : Contient les vecteurs num√©riques dans un format binaire optimis√© par FAISS.
    - `index.pkl` : Un fichier pickle contenant le mapping entre les index des vecteurs et les m√©tadonn√©es des documents (`docstore`).

##### M√©tadonn√©es associ√©es :
- Chaque chunk vectoris√© conserve un ensemble riche de m√©tadonn√©es extraites de l'√©v√©nement original. Ces m√©tadonn√©es sont cruciales pour filtrer, afficher et contextualiser les r√©sultats de recherche.
- **Champs conserv√©s** : `event_id`, `title`, `city`, `date_debut`, `date_fin`, `location` (coordonn√©es GPS), `region`, `keywords`.

### API et endpoints expos√©s
##### Framework utilis√© : FastAPI
- L'API est d√©velopp√©e avec **FastAPI**, un framework Python moderne et performant, et servie par **Uvicorn**, un serveur ASGI. Ce choix garantit des temps de r√©ponse rapides et une scalabilit√© ais√©e.

##### Endpoints cl√©s :
- **`POST /ask`** : Le c≈ìur du syst√®me RAG. Prend une question en JSON, effectue une recherche s√©mantique pour trouver des contextes pertinents, enrichit un prompt et interroge le LLM (Mistral) pour g√©n√©rer une r√©ponse factuelle.
- **`POST /search`** : Endpoint de recherche s√©mantique pure. Il retourne les `k` documents les plus pertinents de la base vectorielle avec leurs scores de similarit√©, sans passer par le LLM.
- **`POST /rebuild`** : D√©clenche le pipeline de mise √† jour incr√©mentale de l'index en arri√®re-plan. Il est non-bloquant et v√©rifie au pr√©alable si de nouveaux √©v√©nements justifient une mise √† jour.
- **`GET /rebuild/status`** : Permet de suivre l'√©tat d'avancement du pipeline de reconstruction (ex: `running`, `success`, `error`).
- **`GET /health`** et **`GET /stats`** : Endpoints de monitoring pour v√©rifier l'√©tat de sant√© de l'API et les statistiques de l'index (nombre de vecteurs, etc.).

##### Format des requ√™tes/r√©ponses
- Les formats sont valid√©s par des mod√®les **Pydantic** pour assurer la robustesse.
- **Requ√™te `/ask`** : `{"question": "...", "k": 5}`
- **R√©ponse `/ask`** :
  ```json
  {
    "question": "...",
    "answer": "...",
    "context_used": [ { "score": 0.8, "title": "...", ... } ],
    "tokens_used": { "prompt_tokens": ..., "total_tokens": ... }
  }
  ```

##### Exemple d‚Äôappel API : avec curl
- **Pour poser une question au RAG :**
  ```bash
  curl -X POST http://localhost:8000/ask \
    -H "Content-Type: application/json" \
    -d '{"question": "Quels sont les festivals de jazz en Occitanie ?", "k": 5}'
  ```
- **Pour lancer une reconstruction de l'index :**
  ```bash
  curl -X POST http://localhost:8000/rebuild
  ```

##### Tests effectu√©s et document√©s
- Le projet inclut une suite de tests unitaires compl√®te utilisant **Pytest** et **HTTPX**.
- Les d√©pendances externes (FAISS, Mistral) sont **mock√©es** pour isoler les tests de l'API.
- Des tests d'√©valuation de la qualit√© du RAG sont √©galement impl√©ment√©s avec **RAGAS** (`make test-ragas`) pour mesurer la pertinence et la fid√©lit√© des r√©ponses.

##### Gestion des erreurs / limitations
- L'API utilise les `HTTPException` de FastAPI pour retourner des codes d'erreur standards (422 pour une requ√™te invalide, 503 si un service est indisponible, 500 pour une erreur interne).
- L'endpoint `/rebuild` est prot√©g√© contre les ex√©cutions concurrentes.

7. √âvaluation du syst√®me
Jeu de test annot√© :
Nombre d‚Äôexemples
M√©thode d‚Äôannotation
M√©triques d‚Äô√©valuation :
Exemple : similarit√© s√©mantique, taux de couverture des r√©ponses, score de satisfaction (subjectif)
R√©sultats obtenus :
Analyse quantitative (scores globaux)
Analyse qualitative (exemples de bonnes/mauvaises r√©ponses)

8. Recommandations et perspectives
Ce qui fonctionne bien
Limites du POC :
Volum√©trie, performance, co√ªt, couverture th√©matique ?
Am√©liorations possibles :
Ajout de‚Ä¶Am√©lioration de..
Passage en production via‚Ä¶

9.  Organisation du d√©p√¥t GitHub
Arborescence du d√©p√¥t (fichiers cl√©s, scripts, dossiers)
Explication rapide de chaque r√©pertoire

10. Annexes (exemples)
Extraits du jeu de test annot√©
Prompt utilis√© (si sp√©cifique)
Extraits de logs ou exemples de r√©ponse JSON
