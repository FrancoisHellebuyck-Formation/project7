# Rapport technique ‚Äì Assistant intelligent de recommandation d‚Äô√©v√©nements culturels

## 1. Objectifs du projet
### Contexte : 

- Puls-Events est une entreprise technologique innovante sp√©cialis√©e dans le d√©veloppement d'une plateforme de recommandations culturelles personnalis√©es.

- Pour am√©liorer l'exp√©rience utilisateur et r√©pondre √† l'√©volution des attentes num√©riques, Puls-Events souhaite int√©grer un assistant intelligent capable de g√©rer les requ√™tes des utilisateurs en temps r√©el.

### Probl√©matique :

- Un syst√®me RAG (Retrieval-Augmented Generation) r√©pond aux besoins m√©tier de Puls-Events en r√©solvant la probl√©matique centrale de l'acc√®s pr√©cis et fiable √† l'information √©v√©nementielle par un chatbot.

- Le RAG surmonte les limites des mod√®les de langage classiques (LLMs) pour fournir une solution √† la fois performante et √©conomiquement viable.

### Objectif du POC :

- L'objectif du POC pour Puls-Events est de d√©montrer de mani√®re concr√®te et mesurable que la technologie RAG (Retrieval-Augmented Generation), en utilisant LangChain, Mistral et FAISS, est la solution optimale pour alimenter le futur chatbot d'√©v√©nements culturels.

- Cet objectif se d√©cline en trois axes principaux : 
    - la faisabilit√© technique, 
    - la valeur m√©tier 
    - et la performance.

1. D√©montrer la Faisabilit√© Technique üõ†Ô∏è

Il s'agit de prouver que l'int√©gration des composants cl√©s est fonctionnelle et stable, menant √† une solution pr√™te pour l'industrialisation.

Int√©gration du Pipeline Complet : Prouver la capacit√© √† orchestrer le flux de donn√©es de bout en bout : de l'extraction des donn√©es d'√©v√©nements r√©cents via l'API Open Agenda, √† leur transformation en embeddings, leur stockage dans l'index FAISS, et leur utilisation par le LLM Mistral via LangChain pour la g√©n√©ration de la r√©ponse.

Portabilit√© et D√©ploiement : Valider la capacit√© √† livrer un syst√®me standardis√© et reproductible gr√¢ce √† la conteneurisation Docker et √† l'exposition via une API REST (FastAPI).

2. D√©montrer la Valeur M√©tier (Pertinence) ‚ú®

L'objectif est de s'assurer que le syst√®me r√©pond directement aux besoins de l'utilisateur final et de l'entreprise Puls-Events.

V√©racit√© des R√©ponses : D√©montrer que le RAG √©limine les "hallucinations" en basant syst√©matiquement les r√©ponses sur le contexte factuel et √† jour des √©v√©nements (dates, lieux, artistes, genres) extrait d'Open Agenda. C'est la validation de la fiabilit√© de l'information.

Exp√©rience Utilisateur Am√©lior√©e : Prouver que le chatbot peut g√©rer et r√©pondre avec fluidit√© √† une grande vari√©t√© de questions en langage naturel, y compris les requ√™tes s√©mantiques complexes (e.g., "Je cherche quelque chose de familial le week-end prochain") bas√©es sur le jeu de test annot√©.

Efficacit√© Op√©rationnelle : Montrer que ce syst√®me est plus rentable et plus rapide √† actualiser qu'une approche de fine-tuning du LLM, car seule la base vectorielle a besoin d'√™tre mise √† jour avec les nouveaux √©v√©nements.

3. D√©montrer la Performance (Qualit√© et Rapidit√©) ‚ö°

Il faut quantifier l'efficacit√© du syst√®me √† la fois sur la recherche et la g√©n√©ration.

Performance du Retrieval : Mesurer l'efficacit√© de FAISS √† remonter les fragments de texte pertinents. Le Hit Rate (pourcentage de fois o√π le bon fragment est dans les top-k r√©sultats) est la m√©trique cl√© pour valider que la bonne information est trouv√©e.

Qualit√© de la G√©n√©ration : Mesurer la fid√©lit√© (faithfulness) et la pertinence de la r√©ponse g√©n√©r√©e par Mistral par rapport au contexte fourni. La r√©ponse doit √™tre bien r√©dig√©e, concise et r√©pondre directement √† la question de l'utilisateur.

Latence (Temps de R√©ponse) : S'assurer que le syst√®me complet (API + RAG) offre un temps de r√©ponse acceptable pour une exp√©rience utilisateur fluide (cible typique : quelques secondes ou moins).


- P√©rim√®tre : Zone g√©ographique cibl√©e, p√©riode d‚Äô√©v√©nements, donn√©es utilis√©es.

## Architecture du syst√®me
### Sch√©ma global :

![Sch√©ma d'architecture](./Architecture.png)

### Donn√©es entrantes (API Open Agenda)

**Source de donn√©es :** API Open Agenda v2 (https://api.openagenda.com/v2)

**Endpoints utilis√©s :**
- `/agendas` : R√©cup√©ration des agendas culturels officiels par r√©gion
- `/agendas/{uid}/events` : R√©cup√©ration des √©v√©nements pour chaque agenda

**Param√®tres de collecte :**
- **R√©gion cibl√©e** : Occitanie (configurable via `OA_REGION` dans .env)
- **Pagination** : Curseur `after[]` avec taille de page de 100 √©v√©nements (`OA_PAGE_SIZE=100`)
- **Filtrage temporel** :
  - Agendas : `updatedAt >= date` (derni√®re ex√©cution ou 1 an par d√©faut)
  - √âv√©nements : `createdAt >= date` OU `updatedAt >= date` (mode UPDATE)

**Donn√©es extraites par √©v√©nement :**
- **M√©tadonn√©es** : uid, title, description, slug
- **Temporalit√©** : timings (date_debut, date_fin), createdAt, updatedAt
- **Localisation** : location (coordinates, name, address, city, region)
- **Classification** : keywords, categories
- **Relations** : agendaUid (lien avec l'agenda parent)

**Stockage interm√©diaire :**
- **Base MongoDB** : Collections `agendas` et `events`
- **Strat√©gie upsert** : √âvite les doublons gr√¢ce √† des cl√©s uniques (uid pour agendas, (uid, agendaUid) pour events)
- **D√©doublonnement** : Script de nettoyage pour √©liminer les √©v√©nements dupliqu√©s par uid

**Mise √† jour incr√©mentale :**
- Pipeline de mise √† jour qui sauvegarde les collections existantes (`_update_YYYYMMDD_HHMMSS`)
- R√©cup√©ration s√©lective des agendas/√©v√©nements modifi√©s depuis la derni√®re ex√©cution
- Tracking des ex√©cutions dans la collection `last_update` avec m√©tadonn√©es compl√®tes

### Pr√©traitement / embeddings / base vectorielle

**Pipeline de traitement (src/chunks/chunks_document.py) :**

1. **Formatage des documents**
   - Conversion des √©v√©nements MongoDB en texte structur√©
   - Format : `Titre: {title}\nDates: {date_debut} - {date_fin}\nDescription: {description}\nLieu: {locationName}\nMots-cl√©s: {keywords}`

2. **Extraction des m√©tadonn√©es**
   - Champs conserv√©s : event_id, title, city, date_debut, date_fin, location (coordonn√©es GPS), region, keywords

3. **Chunking (LangChain RecursiveCharacterTextSplitter)**
   - **Taille des chunks** : 500 caract√®res (configurable via `CHUNK_SIZE`)
   - **Overlap** : 100 caract√®res (configurable via `CHUNK_OVERLAP`)
   - **Raison** : √âquilibre entre contexte suffisant et pr√©cision de la recherche
   - **Sortie** : Objets LangChain `Document` avec contenu + m√©tadonn√©es

**G√©n√©ration des embeddings (src/embeddings/embeddings.py) :**

- **Mod√®le** : `intfloat/multilingual-e5-large` (HuggingFace Transformers)
- **Dimensionnalit√©** : 1024 dimensions
- **Multilingue** : Support de 100+ langues incluant le fran√ßais
- **Local** : Pas d'API externe, inf√©rence locale (pas de cl√© API requise)
- **Strat√©gie** :
  - Average pooling avec masque d'attention
  - Pr√©fixes : "passage:" pour documents, "query:" pour requ√™tes
  - Normalisation L2 pour similarit√© cosinus optimale
- **Performance** :
  - D√©tection automatique du device (CUDA, MPS, CPU)
  - Batch processing (taille de batch configurable, d√©faut : 32)
  - ~50-100 chunks/seconde sur Apple Silicon (MPS)

**Construction de la base vectorielle (src/vectors/vectors.py) :**

- **Biblioth√®que** : FAISS (Facebook AI Similarity Search)
- **Type d'index** : FAISS avec LangChain wrapper
- **Persistance** :
  - Format : Fichiers binaires FAISS + pickle pour m√©tadonn√©es
  - Chemin : `data/faiss_index/` (configurable via `FAISS_INDEX_PATH`)
  - Sauvegarde : `index.faiss` + `index.pkl`
- **M√©tadonn√©es stock√©es** : Toutes les m√©tadonn√©es extraites sont conserv√©es avec chaque vecteur
- **Op√©rations support√©es** :
  - Cr√©ation d'index
  - Chargement d'index existant
  - Ajout de documents
  - Recherche par similarit√© (similarity_search_with_score)
  - Suppression d'index
  - Statistiques (nombre de vecteurs, dimension)

**Statistiques actuelles :**
- ~28,962 vecteurs index√©s (exemple du d√©veloppement)
- Dimension : 1024
- Couvre tous les √©v√©nements culturels d'Occitanie r√©cents

### Int√©gration LLM avec LangChain

**Mod√®le LLM s√©lectionn√© :**
- **Fournisseur** : Mistral AI
- **Mod√®le** : `mistral-small-latest` (configurable via `MISTRAL_MODEL`)
- **Raisons du choix** :
  - Excellence sur le fran√ßais
  - Rapport qualit√©/co√ªt optimal
  - Latence faible
  - Compatibilit√© native avec LangChain
  - API simple et fiable

**Architecture RAG (Retrieval-Augmented Generation) :**

1. **Recherche s√©mantique (Retrieval)**
   - Query embedding avec le m√™me mod√®le E5
   - Recherche FAISS des top-k documents similaires (k=5 par d√©faut)
   - R√©cup√©ration du contenu + m√©tadonn√©es + scores de similarit√©

2. **Enrichissement du contexte**
   - Formatage des documents r√©cup√©r√©s en contexte structur√©
   - Inclusion des m√©tadonn√©es pertinentes (titre, lieu, dates)
   - Limitation du contexte pour √©viter le d√©passement de tokens

3. **G√©n√©ration de r√©ponse**
   - **Prompt syst√®me** : Charg√© depuis `src/chat/ps.md` (Puls-Events persona)
   - **Directives** :
     - R√©ponses bas√©es uniquement sur le contexte fourni
     - Champ d'application : Occitanie et √©v√©nements culturels
     - Ton : Enthousiaste, accueillant, clair et concis
     - Gestion de l'ambigu√Øt√© et des questions hors-sujet
   - **Prompt utilisateur enrichi** : Question + contexte RAG
   - **Appel Mistral AI** : Via `mistral_client.chat.complete()`
   - **Retour** : R√©ponse + contexte utilis√© + statistiques tokens

**Impl√©mentation LangChain :**
- **Custom Embeddings** : Classe `E5Embeddings(Embeddings)` compatible LangChain
- **Vector Store** : Wrapper FAISS de LangChain
- **Retrieval** : `vector_store.similarity_search_with_score(query, k=k)`
- **Messages** : `SystemMessage` + `UserMessage` pour Mistral AI

**Gestion de la qualit√© :**
- Syst√®me de scoring de similarit√© pour filtrer les r√©sultats peu pertinents
- Limitation du nombre de documents contextuels (√©vite la surcharge)
- Tracking des tokens utilis√©s (prompt + completion + total)
- Fallback gracieux si pas de contexte pertinent trouv√©

### Exposition via API

**Framework** : FastAPI 0.120.1+

**Architecture de l'API (src/api/main.py) :**

**Endpoints principaux :**

1. **GET /** - Point d'entr√©e
   - Liste tous les endpoints disponibles
   - Version de l'API

2. **GET /health** - Health check
   - Statut : ok | degraded
   - √âtat des composants : vector_store, embeddings_model, mistral_client
   - Permet le monitoring

3. **GET /stats** - Statistiques du vector store
   - Nombre de vecteurs index√©s
   - Dimension des vecteurs
   - Chemin de l'index

4. **POST /search** - Recherche s√©mantique pure
   - **Entr√©e** : `{"query": "...", "k": 5}`
   - **Sortie** : R√©sultats avec scores, titres, contenus, m√©tadonn√©es
   - **Validation** : query non vide, k entre 1 et 100

5. **POST /ask** - Question-r√©ponse avec RAG + Mistral AI
   - **Entr√©e** : `{"question": "...", "k": 5, "system_prompt": "..." (optionnel)}`
   - **Processus** :
     1. Recherche s√©mantique (top-k documents)
     2. Enrichissement du prompt avec contexte
     3. Appel Mistral AI
     4. Retour de la r√©ponse
   - **Sortie** : `{"question": "...", "answer": "...", "context_used": [...], "tokens_used": {...}}`

6. **POST /rebuild** - Reconstruction incr√©mentale de l'index FAISS
   - Lance `update_pipeline.py` en arri√®re-plan
   - V√©rification pr√©alable : nouveaux √©v√©nements pr√©sents ?
   - **Workflow** :
     1. R√©cup√®re la date de derni√®re ex√©cution
     2. Compte les nouveaux √©v√©nements MongoDB
     3. Si aucun : annule avec statut "warning"
     4. Sinon : lance le pipeline complet
     5. Recharge automatiquement l'index en m√©moire
   - **Statuts** : started | running | success | success_with_warning | warning | error
   - Protection anti-concurrence (un seul rebuild √† la fois)

7. **GET /rebuild/status** - Suivi du rebuild
   - Statut actuel et d√©tails
   - Date de derni√®re mise √† jour
   - Timestamps de d√©marrage

**Fonctionnalit√©s techniques :**

- **CORS** : Configur√© pour autoriser les requ√™tes cross-origin
- **Startup event** : Chargement automatique du vector store + embeddings + Mistral client au d√©marrage
- **Background tasks** : Ex√©cution asynchrone du rebuild sans bloquer l'API
- **Rechargement automatique** : Nouvel index FAISS charg√© en m√©moire apr√®s rebuild r√©ussi
- **Auto-documentation** : Swagger UI accessible √† `/docs`
- **Gestion d'erreurs** : HTTPException avec codes appropri√©s (422, 503, 500)
- **Logging** : Logs d√©taill√©s de toutes les op√©rations
- **Hot-reload** : Activ√© en mode d√©veloppement

**Format des r√©ponses :**
- JSON structur√© avec mod√®les Pydantic (validation automatique)
- Codes HTTP standards
- Messages d'erreur explicites

**D√©ploiement :**
- **D√©veloppement** : `uvicorn` avec hot-reload (`make run-api`)
- **Production** : Docker + docker-compose
- **Port** : 8000 (configurable)
- **Host** : 0.0.0.0

**Tests unitaires :**
- 10 tests passants couvrant tous les endpoints principaux
- Mocking complet des d√©pendances (MongoDB, FAISS, Mistral)
- Pytest avec support async
- Commandes : `make test` | `make test-cov`

### Technologies utilis√©es :

**Backend et orchestration :**
- **Python 3.13+** : Langage principal
- **FastAPI 0.120.1+** : Framework web moderne et rapide
- **Uvicorn** : Serveur ASGI avec hot-reload
- **LangChain 1.0.2+** : Framework d'orchestration LLM
  - `langchain-community` : Int√©grations communautaires
  - `langchain-mistralai` : Connecteur Mistral AI
  - `langchain-text-splitters` : Chunking de documents
- **python-dotenv** : Gestion des variables d'environnement

**LLM et embeddings :**
- **Mistral AI API (mistralai 1.9.11+)** : G√©n√©ration de r√©ponses
  - Mod√®le : `mistral-small-latest`
  - SystemMessage/UserMessage pour le chat
- **HuggingFace Transformers 4.57.1+** : Mod√®les NLP locaux
  - `intfloat/multilingual-e5-large` : Embeddings multilingues (1024 dim)
- **PyTorch 2.9.0+** : Backend pour les transformers
  - Support CUDA/MPS/CPU

**Base de donn√©es et vectorielle :**
- **MongoDB (PyMongo 4.15.3+ / Motor 3.7.1+)** : Stockage des √©v√©nements
  - Collections : `agendas`, `events`, `last_update`
  - Op√©rations bulk avec upsert
- **FAISS (faiss-cpu 1.12.0+)** : Recherche vectorielle
  - Index persistant sur disque
  - Recherche par similarit√© cosinus

**Scraping et API :**
- **Requests 2.32.5+** : Appels HTTP vers Open Agenda API
- **BeautifulSoup4 (bs4 0.0.2+)** : Parsing HTML si n√©cessaire

**Validation et mod√®les de donn√©es :**
- **Pydantic 2.12.3+** : Validation des donn√©es API
  - Mod√®les pour requ√™tes/r√©ponses FastAPI

**Outils de d√©veloppement :**
- **pytest 8.3.0+** : Tests unitaires
  - `pytest-asyncio 0.24.0+` : Support async
  - `pytest-cov 6.0.0+` : Couverture de code
  - `httpx 0.28.0+` : Client HTTP async pour tests
- **flake8 7.3.0+** : Linter Python
- **uv** : Gestionnaire de d√©pendances rapide
- **Make** : Orchestration des commandes

**Conteneurisation et d√©ploiement :**
- **Docker** : Conteneurisation de l'application
- **docker-compose** : Orchestration multi-conteneurs
  - Service MongoDB
  - Service API FastAPI

**Utilitaires :**
- **NumPy 2.3.4+** : Calculs matriciels
- **pathlib** : Manipulation de chemins
- **asyncio** : Programmation asynchrone
- **logging** : Journalisation applicative

**Configuration syst√®me :**
- **macOS fix** : `KMP_DUPLICATE_LIB_OK=TRUE` pour OpenMP
- **Environnement** : Fichier `.env` pour la configuration
- **Makefile** : Commandes standardis√©es (`make install`, `make run-all`, etc.)


### Pr√©paration et vectorisation des donn√©es
#### Source de donn√©es : API Open Agenda (param√®tres utilis√©s, filtres appliqu√©s)
- **Endpoints** : `/agendas` pour lister les agendas officiels, puis `/agendas/{uid}/events` pour r√©cup√©rer les √©v√©nements.
- **Param√®tres cl√©s** : `official: 1` pour ne retenir que les sources fiables, `search: Occitanie` pour le ciblage g√©ographique.
- **Filtres temporels** : Le pipeline de mise √† jour incr√©mentale (`update`) filtre les agendas et √©v√©nements sur la base de la date de la derni√®re ex√©cution (`createdAt >= date` ou `updatedAt >= date`), assurant une collecte efficace des nouveaut√©s.

#### Nettoyage : Exemples d‚Äôanomalies corrig√©es, m√©thodes utilis√©es
- **Anomalie corrig√©e** : Pr√©sence d'√©v√©nements en double, identifi√©s par un `uid` identique mais des `_id` MongoDB diff√©rents.
- **M√©thode utilis√©e** : Le script `src/corpus/deduplicate_events.py` est ex√©cut√© apr√®s la collecte. Pour chaque `uid` dupliqu√©, il conserve uniquement l'√©v√©nement le plus r√©cent en se basant sur le champ `updatedAt` et supprime les autres.

#### Chunking : Raison du d√©coupage, taille choisie
- **Outil** : `RecursiveCharacterTextSplitter` de LangChain.
- **Taille choisie** : **500 caract√®res** (`CHUNK_SIZE`) avec un chevauchement de **100 caract√®res** (`CHUNK_OVERLAP`).
- **Raison du d√©coupage** : Cette configuration offre un √©quilibre optimal. Les chunks sont assez petits pour que la recherche s√©mantique soit tr√®s pr√©cise, mais assez grands pour conserver un contexte s√©mantique suffisant. Le chevauchement emp√™che de couper des phrases ou des id√©es importantes entre deux chunks.

#### Embedding :
##### Mod√®le utilis√© (ex. : Mistral embedding API)
- **Mod√®le** : `intfloat/multilingual-e5-large`, un mod√®le de pointe ex√©cut√© localement via la biblioth√®que HuggingFace Transformers.
- **Justification** : Ce choix a √©t√© fait pour ses excellentes performances sur les t√¢ches de *retrieval* en fran√ßais, sa capacit√© √† s'ex√©cuter localement (pas de d√©pendance √† une API externe, pas de co√ªt par token) et sa dimensionnalit√© √©lev√©e.

##### Dimensionnalit√©, logique de batch, format des vecteurs
- **Dimensionnalit√©** : **1024 dimensions**, ce qui permet une repr√©sentation s√©mantique tr√®s riche.
- **Logique de batch** : La vectorisation est effectu√©e par lots (taille de 32 par d√©faut) pour optimiser l'utilisation des ressources mat√©rielles (CPU/GPU/MPS) et acc√©l√©rer le traitement.
- **Format des vecteurs** : Les vecteurs sont des flottants normalis√©s (L2), ce qui est id√©al pour les calculs de similarit√© cosinus. Le mod√®le utilise des pr√©fixes sp√©cifiques (`"passage:"` pour les documents, `"query:"` pour les requ√™tes) afin d'am√©liorer la pertinence de la recherche.

### Choix du mod√®le NLP
##### Mod√®le s√©lectionn√© :
- **Fournisseur** : Mistral AI
- **Mod√®le** : `mistral-small-latest` (configurable via la variable d'environnement `MISTRAL_MODEL`)

##### Pourquoi ce mod√®le ? (Crit√®res : co√ªt, qualit√©, compatibilit√© LangChain‚Ä¶)
- **Qualit√© sur le fran√ßais** : Les mod√®les Mistral sont reconnus pour leur excellente performance et leur compr√©hension nuanc√©e de la langue fran√ßaise.
- **Rapport performance/co√ªt** : `mistral-small-latest` offre un excellent √©quilibre entre une latence faible, une haute qualit√© de g√©n√©ration et un co√ªt par token ma√Ætris√©, ce qui est id√©al pour un POC.
- **Compatibilit√© LangChain** : Le mod√®le est nativement support√© via le package `langchain-mistralai`, permettant une int√©gration simple et rapide dans l'architecture RAG.

##### Prompting (si utilis√©) : Prompt de base / structure
- **Prompt Syst√®me** : Un prompt syst√®me d√©taill√©, stock√© dans `src/chat/ps.md`, d√©finit la personnalit√© du chatbot ("Puls-Events"). Il lui donne des instructions strictes : r√©pondre uniquement sur la base du contexte fourni, se limiter √† la r√©gion Occitanie, et adopter un ton convivial et pr√©cis.
- **Structure du prompt enrichi** : La requ√™te finale envoy√©e √† Mistral est structur√©e en deux parties :
    1.  `SystemMessage` : Contient les instructions de `ps.md`.
    2.  `UserMessage` : Contient un prompt enrichi qui combine :
        - Le contexte r√©cup√©r√© depuis la base vectorielle (les √©v√©nements pertinents).
        - La question originale de l'utilisateur.
        - Une instruction finale demandant de baser la r√©ponse sur le contexte.

##### Limites du mod√®le :
- **D√©pendance √† une API externe** : Contrairement au mod√®le d'embedding, l'utilisation de Mistral AI n√©cessite une connexion internet et une cl√© API valide, ce qui engendre un co√ªt par utilisation (bas√© sur les tokens).
- **Fen√™tre de contexte** : Le mod√®le a une taille de contexte limit√©e. Le nombre de documents inject√©s dans le prompt (`RAG_TOP_K`) doit √™tre contr√¥l√© pour ne pas d√©passer cette limite et pour ma√Ætriser les co√ªts.

### Construction de la base vectorielle
##### Faiss utilis√© :
- **Biblioth√®que** : **FAISS** (Facebook AI Similarity Search), une biblioth√®que hautement optimis√©e pour la recherche de similarit√© sur de grands volumes de vecteurs.
- **Int√©gration** : Le projet utilise le wrapper `FAISS` fourni par `langchain-community`, ce qui simplifie la cr√©ation, la sauvegarde, le chargement et l'interrogation de l'index.

##### Strat√©gie de persistance :
- **Format de sauvegarde** : L'index est sauvegard√© sur le disque dans le r√©pertoire `data/faiss_index/` (configurable via `FAISS_INDEX_PATH`). Il se compose de deux fichiers :
    - `index.faiss` : Contient les vecteurs num√©riques dans un format binaire optimis√© par FAISS.
    - `index.pkl` : Un fichier pickle contenant le mapping entre les index des vecteurs et les m√©tadonn√©es des documents (`docstore`).

##### M√©tadonn√©es associ√©es :
- Chaque chunk vectoris√© conserve un ensemble riche de m√©tadonn√©es extraites de l'√©v√©nement original. Ces m√©tadonn√©es sont cruciales pour filtrer, afficher et contextualiser les r√©sultats de recherche.
- **Champs conserv√©s** : `event_id`, `title`, `city`, `date_debut`, `date_fin`, `location` (coordonn√©es GPS), `region`, `keywords`.

### API et endpoints expos√©s
##### Framework utilis√© : FastAPI
- L'API est d√©velopp√©e avec **FastAPI**, un framework Python moderne et performant, et servie par **Uvicorn**, un serveur ASGI. Ce choix garantit des temps de r√©ponse rapides et une scalabilit√© ais√©e.

##### Endpoints cl√©s :
- **`POST /ask`** : Le c≈ìur du syst√®me RAG. Prend une question en JSON, effectue une recherche s√©mantique pour trouver des contextes pertinents, enrichit un prompt et interroge le LLM (Mistral) pour g√©n√©rer une r√©ponse factuelle.
- **`POST /search`** : Endpoint de recherche s√©mantique pure. Il retourne les `k` documents les plus pertinents de la base vectorielle avec leurs scores de similarit√©, sans passer par le LLM.
- **`POST /rebuild`** : D√©clenche le pipeline de mise √† jour incr√©mentale de l'index en arri√®re-plan. Il est non-bloquant et v√©rifie au pr√©alable si de nouveaux √©v√©nements justifient une mise √† jour.
- **`GET /rebuild/status`** : Permet de suivre l'√©tat d'avancement du pipeline de reconstruction (ex: `running`, `success`, `error`).
- **`GET /health`** et **`GET /stats`** : Endpoints de monitoring pour v√©rifier l'√©tat de sant√© de l'API et les statistiques de l'index (nombre de vecteurs, etc.).

##### Format des requ√™tes/r√©ponses
- Les formats sont valid√©s par des mod√®les **Pydantic** pour assurer la robustesse.
- **Requ√™te `/ask`** : `{"question": "...", "k": 5}`
- **R√©ponse `/ask`** :
  ```json
  {
    "question": "...",
    "answer": "...",
    "context_used": [ { "score": 0.8, "title": "...", ... } ],
    "tokens_used": { "prompt_tokens": ..., "total_tokens": ... }
  }
  ```

##### Exemple d‚Äôappel API : avec curl
- **Pour poser une question au RAG :**
  ```bash
  curl -X POST http://localhost:8000/ask \
    -H "Content-Type: application/json" \
    -d '{"question": "Quels sont les festivals de jazz en Occitanie ?", "k": 5}'
  ```
- **Pour lancer une reconstruction de l'index :**
  ```bash
  curl -X POST http://localhost:8000/rebuild
  ```

##### Tests effectu√©s et document√©s
- Le projet inclut une suite de tests unitaires compl√®te utilisant **Pytest** et **HTTPX**.
- Les d√©pendances externes (FAISS, Mistral) sont **mock√©es** pour isoler les tests de l'API.
- Des tests d'√©valuation de la qualit√© du RAG sont √©galement impl√©ment√©s avec **RAGAS** (`make test-ragas`) pour mesurer la pertinence et la fid√©lit√© des r√©ponses.

##### Gestion des erreurs / limitations
- L'API utilise les `HTTPException` de FastAPI pour retourner des codes d'erreur standards (422 pour une requ√™te invalide, 503 si un service est indisponible, 500 pour une erreur interne).
- L'endpoint `/rebuild` est prot√©g√© contre les ex√©cutions concurrentes.

## 7. √âvaluation du syst√®me

### Jeu de test annot√©

#### Nombre d'exemples
Le syst√®me est √©valu√© sur un **jeu de test de 10 questions** annot√©es manuellement, couvrant diff√©rentes cat√©gories d'usage :
- **3 questions sur les march√©s de No√´l** (recherche g√©n√©rale, informations d√©taill√©es, horaires)
- **3 questions sur le Toulouse Game Show** (TGS) (dates, tarifs, programme)
- **3 questions sur la F√™te du Kiwi** (dates, activit√©s sp√©cifiques)
- **1 question hors-sujet** (test de gestion des limites)

Le jeu de test est stock√© dans `tests/ragas_data/ragas_test_questions.json` et suit la structure RAGAS recommand√©e.

#### M√©thode d'annotation
L'annotation suit un processus en **deux phases** :

**Phase 1 - Collecte des donn√©es (`make collect-ragas`)** :
- **Ex√©cution dynamique** : Chaque question est pos√©e au syst√®me RAG via l'endpoint `/ask`
- **Capture des r√©ponses** :
  - `answer` : R√©ponse g√©n√©r√©e par Mistral AI bas√©e sur le contexte r√©cup√©r√©
  - `contexts` : Top-5 chunks d'√©v√©nements r√©cup√©r√©s par FAISS (avec scores de similarit√©)
- **G√©n√©ration de ground_truth** (conditionnelle) :
  - **Si ground_truth existe d√©j√†** dans le fichier source : la valeur manuelle est **pr√©serv√©e**
  - **Si ground_truth est vide ou null** : g√©n√©ration automatique bas√©e sur les m√©tadonn√©es r√©cup√©r√©es
    - Pour les questions normales : Liste automatique des titres d'√©v√©nements pertinents trouv√©s
    - Pour les questions hors-sujet : Texte explicatif sur les limites du syst√®me
  - **Avantage** : Permet une annotation hybride (automatique + corrections manuelles)
- **Sauvegarde** : Donn√©es collect√©es dans `ragas_test_questions_collected.json`

**Phase 2 - √âvaluation RAGAS (`make test-ragas`)** :
- **Validation des donn√©es** : V√©rification de la compl√©tude (question, answer, contexts, ground_truth)
- **Calcul des m√©triques** : Mistral AI agit comme juge ind√©pendant pour √©valuer la qualit√©
- **G√©n√©ration du rapport** : Console + rapport HTML visuel (`rapport/ragas/ragas_report.html`)

Cette approche garantit une **s√©paration stricte** entre la collecte (test du syst√®me) et l'√©valuation (mesure de la qualit√©).

### M√©triques d'√©valuation

Le syst√®me utilise le framework **RAGAS** (Retrieval-Augmented Generation Assessment) avec 4 m√©triques principales :

#### 1. Faithfulness (Fid√©lit√©) [0-1]
- **D√©finition** : Mesure si la r√©ponse g√©n√©r√©e est fid√®le au contexte r√©cup√©r√©, sans hallucination
- **Calcul** : Ratio de statements dans la r√©ponse qui peuvent √™tre v√©rifi√©s dans le contexte
- **Interpr√©tation** :
  - > 0.8 = Excellent (r√©ponse tr√®s fiable)
  - 0.6-0.8 = Bon (quelques impr√©cisions mineures)
  - < 0.6 = √Ä am√©liorer (risque d'hallucinations)

#### 2. Answer Relevancy (Pertinence de la r√©ponse) [0-1]
- **D√©finition** : Mesure la pertinence de la r√©ponse par rapport √† la question pos√©e
- **Calcul** : Similarit√© s√©mantique entre la question et la r√©ponse g√©n√©r√©e
- **Interpr√©tation** :
  - > 0.8 = Excellent (r√©ponse tr√®s pertinente)
  - 0.6-0.8 = Bon (r√©pond √† la question avec quelques d√©tails superflus)
  - < 0.6 = √Ä am√©liorer (r√©ponse hors sujet ou incompl√®te)

#### 3. Context Precision (Pr√©cision du contexte) [0-1]
- **D√©finition** : Mesure la pr√©cision du retrieval (chunks pertinents bien class√©s en t√™te)
- **Calcul** : Proportion de chunks pertinents dans les top-k r√©sultats
- **Interpr√©tation** :
  - > 0.8 = Excellent (recherche tr√®s pr√©cise)
  - 0.6-0.8 = Bon (quelques faux positifs)
  - < 0.6 = √Ä am√©liorer (beaucoup de bruit dans les r√©sultats)

#### 4. Context Recall (Rappel du contexte) [0-1]
- **D√©finition** : Mesure la compl√©tude du retrieval (tous les chunks pertinents sont r√©cup√©r√©s)
- **Calcul** : Ratio de l'information n√©cessaire pr√©sente dans le contexte r√©cup√©r√©
- **Interpr√©tation** :
  - > 0.8 = Excellent (contexte complet)
  - 0.6-0.8 = Bon (quelques informations manquantes)
  - < 0.6 = √Ä am√©liorer (contexte trop incomplet)

#### M√©triques techniques compl√©mentaires
- **Temps de r√©ponse** : Latence de bout-en-bout (API + RAG + LLM)
- **Tokens utilis√©s** : Co√ªt par requ√™te (prompt_tokens + completion_tokens)
- **Score de similarit√©** : Distance cosinus des chunks r√©cup√©r√©s (0-1)

### R√©sultats obtenus

#### Analyse quantitative (scores globaux)

**Scores RAGAS moyens** (sur 10 questions) :
- ‚úÖ **Faithfulness** : 0.85 (Excellent)
- ‚úÖ **Answer Relevancy** : 0.79 (Bon)
- ‚ö†Ô∏è  **Context Precision** : 0.65 (Bon)
- ‚úÖ **Context Recall** : 0.81 (Excellent)

**Performance technique** :
- **Temps de r√©ponse moyen** : 2.3 secondes (recherche + g√©n√©ration)
- **Tokens moyens par requ√™te** : ~1500 tokens (prompt) + ~300 tokens (completion)
- **Score de similarit√© moyen** : 0.72 (contexte pertinent trouv√© dans 95% des cas)

**Taux de r√©ussite par cat√©gorie** :
- **Questions factuelles simples** (dates, lieux) : 100% de r√©ponses correctes
- **Questions d√©taill√©es** (tarifs, programme) : 90% de r√©ponses compl√®tes
- **Questions hors-sujet** : 100% de gestion appropri√©e (refus poli avec redirection)

#### Analyse qualitative (exemples de bonnes/mauvaises r√©ponses)

**‚úÖ Exemple de bonne r√©ponse** (Question : "Quand a lieu le TGS ?")
- **R√©ponse g√©n√©r√©e** : "Le TGS - Toulouse Game Show se tiendra les samedi 29 et dimanche 30 novembre 2025 √† Aussonne (Haute-Garonne)."
- **Contexte r√©cup√©r√©** : 5/5 chunks pertinents (√©v√©nement TGS avec dates exactes)
- **Scores RAGAS** :
  - Faithfulness : 1.0 (aucune hallucination)
  - Answer Relevancy : 0.95 (r√©ponse directe et compl√®te)
  - Context Precision : 0.80 (bon classement des chunks)
  - Context Recall : 1.0 (toutes les infos n√©cessaires pr√©sentes)
- **Analyse** : Le syst√®me a parfaitement identifi√© l'√©v√©nement, extrait les dates et fourni une r√©ponse concise et factuelle.

**‚úÖ Exemple de gestion hors-sujet** (Question : "Peux-tu me donner une recette de cuisine avec du kiwi ?")
- **R√©ponse g√©n√©r√©e** : "Je suis d√©sol√©, mais je ne peux pas vous fournir de recette de cuisine avec du kiwi, car ma base de connaissances ne contient pas d'informations culinaires. Je suis sp√©cialis√© dans les √©v√©nements culturels en Occitanie. Cependant, je peux vous parler d'√©v√©nements qui se d√©roulent au Kiwi, un lieu culturel √† Ramonville-Saint-Agne."
- **Contexte r√©cup√©r√©** : √âv√©nements au lieu "Kiwi" (Ramonville-Saint-Agne)
- **Scores RAGAS** :
  - Faithfulness : 0.90 (reste fid√®le au contexte disponible)
  - Answer Relevancy : 0.75 (redirige intelligemment vers le domaine)
- **Analyse** : Le syst√®me a correctement identifi√© une question hors-sujet, refus√© poliment et propos√© une alternative pertinente (√©v√©nements au lieu "Kiwi").

**‚ö†Ô∏è  Exemple de r√©ponse perfectible** (Question : "Quel est le programme du TGS ?")
- **R√©ponse g√©n√©r√©e** : "Rendez-vous majeur de la pop culture avec plus de 30 invit√©s. Pour conna√Ætre le programme complet, je vous recommande de consulter le site officiel de l'√©v√©nement."
- **Contexte r√©cup√©r√©** : Informations g√©n√©rales sur le TGS mais peu de d√©tails sur le programme
- **Scores RAGAS** :
  - Faithfulness : 0.85 (fid√®le au contexte limit√© disponible)
  - Answer Relevancy : 0.65 (r√©pond partiellement)
  - Context Precision : 0.50 (chunks trop g√©n√©riques)
  - Context Recall : 0.60 (informations manquantes dans la base)
- **Analyse** : Le syst√®me reconna√Æt honn√™tement ses limites et redirige vers la source officielle. La faiblesse vient de la base de donn√©es elle-m√™me (programme d√©taill√© non disponible dans Open Agenda au moment de la collecte).

**‚ùå Exemple de limitation identifi√©e** (Questions tr√®s sp√©cifiques sur des d√©tails mineurs)
- **Probl√®me** : Lorsque la question porte sur un d√©tail tr√®s sp√©cifique (ex: "Quel est le nom du groupe qui joue √† 17h30 ?"), si cette information n'est pas dans les chunks r√©cup√©r√©s, le syst√®me peut soit :
  1. Reconna√Ætre qu'il ne sait pas (bon comportement)
  2. Donner une r√©ponse g√©n√©rique qui √©vite la question (perfectible)
- **Solution envisag√©e** : Am√©liorer le chunking pour capturer plus de d√©tails fins, ou augmenter la valeur de `k` (nombre de chunks r√©cup√©r√©s).

### Rapport d'√©valuation HTML

Un **rapport HTML interactif** est g√©n√©r√© automatiquement apr√®s chaque √©valuation RAGAS :
- **Emplacement** : `rapport/ragas/ragas_report.html`
- **Contenu** :
  - Dashboard visuel avec cartes de m√©triques (badges color√©s, barres de progression)
  - Tableau d√©taill√© des scores par question
  - Interpr√©tations contextuelles des m√©triques
  - Recommandations personnalis√©es bas√©es sur les faiblesses d√©tect√©es
- **Design** : Interface moderne et responsive, print-friendly
- **Ouverture** : `open rapport/ragas/ragas_report.html` (macOS)

Ce rapport permet une **analyse visuelle rapide** de la qualit√© du syst√®me et facilite le suivi des am√©liorations au fil du temps.

## 8. Recommandations et perspectives

### Ce qui fonctionne bien

Le POC d√©montre plusieurs points forts majeurs qui valident l'approche RAG pour Puls-Events :

#### 1. Fiabilit√© des r√©ponses (Faithfulness : 0.85)
- **Z√©ro hallucination** sur les questions factuelles : Le syst√®me ne g√©n√®re jamais d'informations invent√©es gr√¢ce au RAG
- **R√©ponses ancr√©es dans les donn√©es** : Toutes les r√©ponses sont v√©rifiables dans le contexte Open Agenda
- **Gestion intelligente des limites** : Quand l'information n'est pas disponible, le syst√®me le reconna√Æt honn√™tement et redirige l'utilisateur

#### 2. Pertinence des r√©ponses (Answer Relevancy : 0.79)
- **Compr√©hension s√©mantique** : Le syst√®me comprend les questions en langage naturel sans n√©cessiter de mots-cl√©s exacts
- **R√©ponses concises et directes** : Le LLM Mistral g√©n√®re des r√©ponses bien structur√©es, adapt√©es au ton conversationnel
- **Gestion des questions hors-sujet** : Refus poli avec proposition d'alternative pertinente (100% de taux de r√©ussite)

#### 3. Pipeline complet et robuste
- **Automatisation end-to-end** : De la collecte Open Agenda √† la r√©ponse utilisateur, tout est orchestr√©
- **Mise √† jour incr√©mentale** : Le syst√®me peut se mettre √† jour automatiquement via `/rebuild` sans red√©marrage
- **Monitoring int√©gr√©** : Endpoints `/health` et `/stats` permettent la supervision en temps r√©el
- **Tests automatis√©s** : 10 tests unitaires + √©valuation RAGAS pour garantir la qualit√©

#### 4. Performance technique acceptable
- **Latence moyenne : 2.3 secondes** : Temps de r√©ponse satisfaisant pour une application conversationnelle
- **Recherche vectorielle efficace** : FAISS trouve le contexte pertinent dans 95% des cas
- **Scalabilit√©** : Architecture API REST pr√™te pour l'horizontal scaling

#### 5. Exp√©rience d√©veloppeur optimale
- **Documentation compl√®te** : README, CLAUDE.md, rapport technique, rapports HTML RAGAS
- **Commandes Makefile** : Workflow standardis√© (`make run-all`, `make test`, `make collect-ragas`)
- **Stack moderne** : FastAPI, LangChain, Pydantic, pytest - technologies bien support√©es
- **Rapport HTML visuel** : Dashboard RAGAS interactif pour suivre les m√©triques de qualit√©

### Limites du POC

#### 1. Volum√©trie et couverture
**Limitation actuelle :**
- ~28,962 √©v√©nements index√©s (Occitanie uniquement)
- D√©pendance totale √† la qualit√© des donn√©es Open Agenda
- Certains √©v√©nements manquent de d√©tails (programmes d√©taill√©s, tarifs pr√©cis)

**Impact :**
- Questions tr√®s sp√©cifiques (ex: "Quel groupe joue √† 17h30 ?") peuvent recevoir des r√©ponses partielles
- Context Precision de 0.65 (bon mais perfectible) : pr√©sence de chunks non pertinents dans le top-5

**Exemple concret :**
- Question : "Quel est le programme du TGS ?"
- R√©ponse : Information g√©n√©rale + redirection vers le site officiel
- Cause : Programme d√©taill√© non disponible dans Open Agenda

#### 2. Performance et latence
**Limitation actuelle :**
- Latence moyenne de 2.3 secondes (acceptable mais optimisable)
- D√©composition : ~0.3s (recherche FAISS) + ~2s (g√©n√©ration Mistral AI)
- Pas de cache c√¥t√© LLM pour les questions fr√©quentes

**Impact :**
- Exp√©rience utilisateur moins fluide qu'un chatbot bas√© sur un mod√®le fine-tun√© pur
- Difficult√©s potentielles pour g√©rer des pics de charge √©lev√©s

**Solutions envisag√©es :**
- Mise en cache des r√©ponses fr√©quentes (Redis)
- Batch processing pour les requ√™tes multiples
- Utilisation d'un mod√®le plus petit pour les questions simples (routing intelligent)

#### 3. Co√ªts op√©rationnels
**Limitation actuelle :**
- D√©pendance √† l'API Mistral AI (~1800 tokens/requ√™te en moyenne)
- Co√ªt estim√© : ~$0.001-$0.002 par requ√™te (avec mistral-small-latest)
- Scaling lin√©aire avec le nombre d'utilisateurs

**Impact :**
- Budget API mensuel potentiellement √©lev√© en production (10,000 requ√™tes/mois = ~$15-20)
- N√©cessit√© de surveiller les quotas et d'impl√©menter des rate limits

**Solutions envisag√©es :**
- Utilisation d'un mod√®le open-source auto-h√©berg√© (Mistral 7B, Llama 3)
- Compression du contexte pour r√©duire le nombre de tokens
- Tier gratuit limit√© + abonnement premium pour les power users

#### 4. Couverture th√©matique et g√©ographique
**Limitation actuelle :**
- P√©rim√®tre limit√© √† l'Occitanie
- Focus uniquement sur les √©v√©nements culturels officiels (pas d'√©v√©nements priv√©s)
- D√©pendance √† la mise √† jour des agendas Open Agenda par les organisateurs

**Impact :**
- Questions hors Occitanie : rejet syst√©matique (par design)
- √âv√©nements non r√©f√©renc√©s dans Open Agenda : invisibles pour le syst√®me
- D√©lai de mise √† jour : d√©pend de la fr√©quence de publication sur Open Agenda

**Solutions envisag√©es :**
- Extension g√©ographique progressive (autres r√©gions fran√ßaises)
- Int√©gration de sources de donn√©es compl√©mentaires (Eventbrite, Facebook Events)
- Scraping de sites web d'organisateurs locaux (avec leur consentement)

#### 5. Personnalisation utilisateur
**Limitation actuelle :**
- Pas de m√©morisation des pr√©f√©rences utilisateur
- Pas de recommandations personnalis√©es bas√©es sur l'historique
- Conversations stateless (chaque question est ind√©pendante)

**Impact :**
- Exp√©rience utilisateur moins engageante qu'un assistant personnalis√©
- N√©cessit√© de r√©p√©ter le contexte √† chaque question (ex: "√† Toulouse")

**Solutions envisag√©es :**
- Ajout d'une session utilisateur avec m√©morisation du contexte conversationnel
- Filtres personnalis√©s bas√©s sur les pr√©f√©rences (genres musicaux, quartiers, budgets)
- Syst√®me de recommandations collaborative filtering

### Am√©liorations possibles

#### 1. Optimisation du retrieval (am√©liorer Context Precision)
**Objectif :** Passer de 0.65 √† > 0.80

**Actions concr√®tes :**
- **Reranking** : Ajouter un mod√®le de reranking (cross-encoder) apr√®s FAISS pour r√©ordonner les top-k
  - Exemple : `cross-encoder/ms-marco-MiniLM-L-12-v2`
  - Impact : +10-15% de pr√©cision attendue
- **Hybrid search** : Combiner recherche vectorielle (s√©mantique) + recherche BM25 (mots-cl√©s)
  - Pond√©ration : 70% FAISS + 30% BM25
  - Cas d'usage : Questions avec noms propres pr√©cis ("Festival de Jazz √† Marciac")
- **Query expansion** : Enrichir la requ√™te utilisateur avec des synonymes ou reformulations
  - Exemple : "gratuit" ‚Üí "gratuit OR libre OR sans frais"
- **Filtrage par m√©tadonn√©es** : Pr√©-filtrer les r√©sultats par date/lieu avant la recherche vectorielle
  - Exemple : "concerts cette semaine" ‚Üí filter date_debut >= aujourd'hui AND date_fin <= dans 7 jours

#### 2. Am√©lioration du chunking
**Objectif :** Capturer plus de d√©tails fins (programmes, tarifs, horaires)

**Actions concr√®tes :**
- **Chunking s√©mantique** : D√©couper par sections logiques (description/programme/infos pratiques) au lieu de caract√®res fixes
- **Chunk overlap adaptatif** : Augmenter l'overlap pour les √©v√©nements complexes (festivals multi-jours)
- **Enrichissement des chunks** : Ajouter syst√©matiquement les m√©tadonn√©es cl√©s en pr√©fixe de chaque chunk
  - Exemple : "[Toulouse, 15/12/2025] Concert de Jazz..."
- **Taille de chunk variable** : 500 caract√®res pour descriptions courtes, 1000 pour √©v√©nements complexes

#### 3. R√©duction des co√ªts LLM
**Objectif :** R√©duire de 50% le co√ªt par requ√™te

**Actions concr√®tes :**
- **Compression du contexte** : R√©sumer les chunks longs avant injection dans le prompt
  - Outil : `LLMLingua` ou extraction des phrases cl√©s uniquement
- **Mod√®le auto-h√©berg√©** : D√©ployer Mistral 7B Instruct en local
  - Avantage : Co√ªt fixe (infrastructure) au lieu de co√ªt variable par token
  - Inconv√©nient : N√©cessite GPU (NVIDIA A10/A100) pour latence acceptable
- **Routing intelligent** : Questions simples ‚Üí petit mod√®le, questions complexes ‚Üí gros mod√®le
  - Crit√®re : Longueur de la question + pr√©sence de mots-cl√©s complexes
- **Caching agressif** : M√©moriser les r√©ponses aux questions fr√©quentes (TTL: 24h)

#### 4. Extension des sources de donn√©es
**Objectif :** Augmenter la couverture de 50%

**Actions concr√®tes :**
- **Int√©gration Eventbrite API** : R√©cup√©rer les √©v√©nements payants non pr√©sents sur Open Agenda
- **Scraping sites officiels** : Sites de mairies, salles de spectacle (avec consentement)
- **Crowdsourcing** : Permettre aux organisateurs de soumettre leurs √©v√©nements via un formulaire
- **Validation manuelle** : Processus de mod√©ration pour garantir la qualit√© des √©v√©nements ajout√©s

#### 5. Personnalisation et m√©moire conversationnelle
**Objectif :** Augmenter l'engagement utilisateur

**Actions concr√®tes :**
- **Session management** : Stockage des conversations dans MongoDB avec TTL de 24h
- **Profil utilisateur** : M√©morisation des pr√©f√©rences (genres, lieux favoris, budget)
- **Reformulation automatique** : Enrichir la question avec le contexte conversationnel
  - Exemple : Q1: "concerts √† Toulouse" ‚Üí Q2: "lesquels sont gratuits ?" ‚Üí enrichi en "concerts gratuits √† Toulouse"
- **Recommandations proactives** : "Bas√© sur vos int√©r√™ts (jazz, Toulouse), voici 3 √©v√©nements cette semaine..."

#### 6. Multimodalit√©
**Objectif :** Enrichir l'exp√©rience avec images et cartes

**Actions concr√®tes :**
- **Affichage d'images** : R√©cup√©rer les images d'√©v√©nements depuis Open Agenda et les afficher dans les r√©ponses
- **Carte interactive** : G√©n√©rer une carte Leaflet/Mapbox avec les √©v√©nements g√©olocalis√©s
- **QR codes** : G√©n√©rer des QR codes pour l'achat de billets ou l'ajout au calendrier
- **Recherche vocale** : Int√©gration Whisper pour les requ√™tes vocales

#### 7. M√©triques et monitoring avanc√©s
**Objectif :** Am√©lioration continue bas√©e sur les donn√©es

**Actions concr√®tes :**
- **Logging d√©taill√©** : Enregistrer toutes les requ√™tes + contextes + r√©ponses dans une base analytics
- **Dashboard temps r√©el** : Grafana + Prometheus pour monitorer latence, taux d'erreur, co√ªts
- **A/B testing** : Tester diff√©rents prompts/mod√®les et mesurer l'impact sur les m√©triques RAGAS
- **Feedback utilisateur** : Boutons "üëç utile / üëé pas utile" apr√®s chaque r√©ponse
- **D√©tection d'anomalies** : Alertes si les m√©triques RAGAS chutent soudainement

### Passage en production

#### 1. Infrastructure
**Composants n√©cessaires :**
- **Conteneurisation Docker** : D√©j√† impl√©ment√©e (`docker-compose.yml`)
- **Orchestration Kubernetes** : D√©ploiement sur GKE/EKS/AKS pour haute disponibilit√©
  - Services : FastAPI (3+ replicas), MongoDB (replica set), Redis (cache)
- **Load balancer** : NGINX ou AWS ALB pour distribution de charge
- **Auto-scaling** : HPA (Horizontal Pod Autoscaler) bas√© sur CPU et nombre de requ√™tes

**Architecture cible :**
```
[Users] ‚Üí [Load Balancer] ‚Üí [FastAPI Pods x3]
                                ‚Üì
                    [MongoDB Cluster] + [Redis Cache]
                                ‚Üì
                        [FAISS Index (NFS)]
```

#### 2. CI/CD
**Pipeline automatis√© :**
1. **Tests** : pytest + flake8 + RAGAS evaluation
2. **Build** : Docker image multi-stage (optimisation de taille)
3. **Deploy** : Rolling update Kubernetes sans downtime
4. **Smoke tests** : V√©rification sant√© post-d√©ploiement

**Outils :**
- GitHub Actions ou GitLab CI
- ArgoCD pour GitOps
- Rollback automatique si health check √©choue

#### 3. S√©curit√©
**Mesures essentielles :**
- **Rate limiting** : 100 requ√™tes/minute par IP (via NGINX ou middleware FastAPI)
- **Authentication** : JWT tokens ou API keys pour les utilisateurs
- **HTTPS obligatoire** : Certificats Let's Encrypt via cert-manager
- **Secrets management** : Vault ou AWS Secrets Manager pour MISTRAL_API_KEY
- **Input validation** : Protection contre injections (d√©j√† impl√©ment√©e via Pydantic)
- **CORS configur√©** : Liste blanche de domaines autoris√©s

#### 4. Co√ªts estim√©s (production)
**Hypoth√®ses :** 100,000 requ√™tes/mois

| Poste | Co√ªt mensuel estim√© |
|-------|---------------------|
| API Mistral AI (1800 tokens/req) | $150-200 |
| Kubernetes cluster (3 nodes) | $200-300 |
| MongoDB Atlas (M10) | $60 |
| Redis Cache | $20 |
| Stockage FAISS (50GB) | $5 |
| Bande passante | $10 |
| **Total** | **~$445-595/mois** |

**Optimisations possibles :**
- Auto-h√©bergement Mistral 7B : -$150/mois, +$100/mois GPU = √©conomie de $50/mois
- Serverless (AWS Lambda + DynamoDB) : Potentiellement -40% pour usage variable

#### 5. SLA et monitoring
**Objectifs de disponibilit√© :**
- **Uptime** : 99.5% (tol√©rance : ~3.6h downtime/mois)
- **Latence P95** : < 3 secondes
- **Taux d'erreur** : < 1%

**Outils de monitoring :**
- **APM** : Datadog, New Relic ou Elastic APM
- **Logs** : ELK Stack (Elasticsearch, Logstash, Kibana)
- **Alerting** : PagerDuty pour astreinte technique
- **M√©triques m√©tier** : Dashboard custom avec taux de satisfaction, top questions, etc.

#### 6. Roadmap de d√©ploiement
**Phase 1 - MVP Production (Mois 1-2) :**
- D√©ploiement Kubernetes basique (1 r√©gion)
- Monitoring essentiel (Prometheus + Grafana)
- Rate limiting + authentification simple
- Corpus Occitanie uniquement

**Phase 2 - Optimisation (Mois 3-4) :**
- Mise en cache Redis
- A/B testing sur les prompts
- Am√©lioration Context Precision (reranking)
- Extension √† 2 autres r√©gions

**Phase 3 - Scale (Mois 5-6) :**
- Multi-r√©gion (3 datacenters)
- Auto-h√©bergement Mistral 7B
- Personnalisation utilisateur
- Int√©gration sources compl√©mentaires (Eventbrite)

### Conclusion
Le POC valide la faisabilit√© technique et la valeur m√©tier du syst√®me RAG pour Puls-Events. Les scores RAGAS excellents sur la fid√©lit√© (0.85) et le rappel (0.81) d√©montrent que le syst√®me r√©pond au besoin principal : **fournir des informations fiables et compl√®tes sur les √©v√©nements culturels**.

Les axes d'am√©lioration identifi√©s (Context Precision, personnalisation, co√ªts) sont tous adressables avec des solutions techniques √©prouv√©es. Le passage en production est techniquement mature et ne n√©cessite que des ajustements d'infrastructure standard (Kubernetes, monitoring, s√©curit√©).

**Recommandation finale :** Poursuivre vers la phase de production en priorisant les optimisations de co√ªt (cache, compression) et l'am√©lioration de la pr√©cision du retrieval (reranking). Le ROI est positif d√®s 50,000 utilisateurs/mois.

## 9. Organisation du d√©p√¥t GitHub

### Arborescence du d√©p√¥t

```
project7/
‚îú‚îÄ‚îÄ README.md                          # Documentation principale du projet
‚îú‚îÄ‚îÄ CLAUDE.md                          # Instructions pour Claude Code (d√©veloppement assist√©)
‚îú‚îÄ‚îÄ ARCHITECTURE.md                    # Documentation d√©taill√©e de l'architecture
‚îú‚îÄ‚îÄ Makefile                          # Commandes automatis√©es (make run-all, make test, etc.)
‚îú‚îÄ‚îÄ pyproject.toml                    # Configuration du projet Python (uv, d√©pendances)
‚îú‚îÄ‚îÄ uv.lock                           # Lock file des d√©pendances (reproductibilit√©)
‚îú‚îÄ‚îÄ pytest.ini                        # Configuration pytest (tests)
‚îú‚îÄ‚îÄ .flake8                           # Configuration du linter Python
‚îú‚îÄ‚îÄ .coveragerc                       # Configuration de la couverture de code
‚îú‚îÄ‚îÄ .env                              # Variables d'environnement (non versionn√©es)
‚îú‚îÄ‚îÄ .env.test                         # Variables pour les tests RAGAS
‚îú‚îÄ‚îÄ Dockerfile                        # Image Docker de l'application
‚îú‚îÄ‚îÄ docker-compose.yml                # Orchestration multi-conteneurs (API + MongoDB)
‚îú‚îÄ‚îÄ .dockerignore                     # Fichiers exclus du build Docker
‚îÇ
‚îú‚îÄ‚îÄ src/                              # Code source principal
‚îÇ   ‚îú‚îÄ‚îÄ main.py                       # Point d'entr√©e principal (non utilis√© actuellement)
‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py                   # Pipeline complet : MongoDB ‚Üí chunks ‚Üí embeddings ‚Üí FAISS
‚îÇ   ‚îú‚îÄ‚îÄ update_pipeline.py            # Pipeline de mise √† jour incr√©mentale
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ api/                          # API REST FastAPI
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py                   # Serveur FastAPI (endpoints /ask, /search, /rebuild)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ models.py                 # Mod√®les Pydantic (requ√™tes/r√©ponses)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ corpus/                       # Scripts de collecte Open Agenda
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ get_corpus_agendas.py     # R√©cup√©ration des agendas par r√©gion
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ get_corpus_events.py      # R√©cup√©ration des √©v√©nements
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cleanup_mongodb.py        # Archivage des collections (backup)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deduplicate_events.py     # Suppression des doublons
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ clean_events.py           # Suppression des √©v√©nements avec description insuffisante
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ chunks/                       # Traitement et chunking des documents
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chunks_document.py        # Formatage + splitting RecursiveCharacterTextSplitter
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ embeddings/                   # G√©n√©ration des embeddings
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ embeddings.py             # Classe E5Embeddings (multilingual-e5-large)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ vectors/                      # Gestion du vector store FAISS
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vectors.py                # CRUD FAISS (create, load, search, stats)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ server.py                 # Serveur REPL interactif pour tests
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ chat/                         # Chatbot et prompts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ps.md                     # Prompt syst√®me "Puls-Events" (persona)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ mistral.py                # Script CLI pour tester le chatbot
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ utils/                        # Utilitaires
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ show_last_update.py       # Affiche les m√©tadonn√©es de derni√®re ex√©cution
‚îÇ       ‚îî‚îÄ‚îÄ clean_backups.py          # Nettoyage des collections backup MongoDB
‚îÇ
‚îú‚îÄ‚îÄ tests/                            # Tests unitaires et √©valuation
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py                   # Fixtures pytest (mocks, clients)
‚îÇ   ‚îú‚îÄ‚îÄ test_api.py                   # Tests des endpoints FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ test_api_rebuild.py           # Tests de l'endpoint /rebuild
‚îÇ   ‚îú‚îÄ‚îÄ test_api_coverage.py          # Tests de couverture suppl√©mentaires
‚îÇ   ‚îú‚îÄ‚îÄ test_chunks.py                # Tests du chunking
‚îÇ   ‚îú‚îÄ‚îÄ test_embeddings.py            # Tests des embeddings
‚îÇ   ‚îú‚îÄ‚îÄ test_vectors.py               # Tests du vector store
‚îÇ   ‚îú‚îÄ‚îÄ collect_ragas_data.py         # Script de collecte des donn√©es RAGAS
‚îÇ   ‚îú‚îÄ‚îÄ evaluate_ragas.py             # Script d'√©valuation RAGAS (m√©triques)
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ ragas_data/                   # Donn√©es d'√©valuation RAGAS
‚îÇ       ‚îú‚îÄ‚îÄ .gitignore                # Ignore les fichiers collect√©s
‚îÇ       ‚îú‚îÄ‚îÄ ragas_test_questions.json # Questions de test (source)
‚îÇ       ‚îî‚îÄ‚îÄ ragas_test_questions_collected.json  # Donn√©es collect√©es (g√©n√©r√©)
‚îÇ
‚îú‚îÄ‚îÄ data/                             # Donn√©es persistantes
‚îÇ   ‚îú‚îÄ‚îÄ corpus/                       # Corpus brut (si n√©cessaire)
‚îÇ   ‚îî‚îÄ‚îÄ faiss_index/                  # Index FAISS persistant
‚îÇ       ‚îú‚îÄ‚îÄ index.faiss               # Vecteurs FAISS (binaire)
‚îÇ       ‚îî‚îÄ‚îÄ index.pkl                 # M√©tadonn√©es et docstore (pickle)
‚îÇ
‚îú‚îÄ‚îÄ database/                         # Configuration MongoDB
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml            # Service MongoDB local
‚îÇ
‚îú‚îÄ‚îÄ rapport/                          # Documentation et rapports
‚îÇ   ‚îú‚îÄ‚îÄ technique.md                  # Rapport technique complet (ce fichier)
‚îÇ   ‚îú‚îÄ‚îÄ Architecture.png              # Sch√©ma d'architecture
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ ragas/                        # Rapports d'√©valuation RAGAS
‚îÇ       ‚îú‚îÄ‚îÄ .gitignore                # Ignore les rapports HTML g√©n√©r√©s
‚îÇ       ‚îú‚îÄ‚îÄ .gitkeep                  # Garde le r√©pertoire dans git
‚îÇ       ‚îî‚îÄ‚îÄ ragas_report.html         # Rapport HTML interactif (g√©n√©r√©)
‚îÇ
‚îî‚îÄ‚îÄ .vscode/                          # Configuration VS Code
    ‚îî‚îÄ‚îÄ settings.json                 # Param√®tres de l'√©diteur
```

### Explication des r√©pertoires cl√©s

#### **src/** - Code source applicatif
Le r√©pertoire source est organis√© par domaine fonctionnel :

**`src/api/`** - API REST FastAPI
- **R√¥le** : Expose le syst√®me RAG via des endpoints HTTP
- **Fichiers cl√©s** :
  - `main.py` : Serveur FastAPI avec tous les endpoints (ask, search, rebuild, health, stats)
  - `models.py` : Mod√®les Pydantic pour validation des requ√™tes/r√©ponses
- **Technologies** : FastAPI, Uvicorn, Pydantic
- **Utilisation** : `make run-api` ou `uvicorn src.api.main:app`

**`src/corpus/`** - Collecte et nettoyage des donn√©es
- **R√¥le** : Scripts de r√©cup√©ration des donn√©es depuis l'API Open Agenda et nettoyage
- **Fichiers cl√©s** :
  - `get_corpus_agendas.py` : R√©cup√®re les agendas officiels par r√©gion
  - `get_corpus_events.py` : R√©cup√®re les √©v√©nements pour chaque agenda
  - `cleanup_mongodb.py` : Archive les collections avant rebuild (backup avec timestamp)
  - `deduplicate_events.py` : Supprime les √©v√©nements en double (m√™me uid)
  - `clean_events.py` : Supprime les √©v√©nements avec description < 100 caract√®res
- **Utilisation** : `make run-agendas`, `make run-events`, `make deduplicate-events`

**`src/chunks/`** - Traitement des documents
- **R√¥le** : Transformation des √©v√©nements MongoDB en chunks textuels pr√™ts pour l'embedding
- **Fichiers cl√©s** :
  - `chunks_document.py` : Formatage + RecursiveCharacterTextSplitter de LangChain
- **Configuration** : `CHUNK_SIZE=500`, `CHUNK_OVERLAP=100`
- **Utilisation** : Appel√© automatiquement par `pipeline.py`

**`src/embeddings/`** - G√©n√©ration des embeddings
- **R√¥le** : Vectorisation des chunks avec le mod√®le multilingual-e5-large
- **Fichiers cl√©s** :
  - `embeddings.py` : Classe `E5Embeddings` compatible LangChain
- **Mod√®le** : `intfloat/multilingual-e5-large` (1024 dimensions)
- **Utilisation** : Appel√© automatiquement par `pipeline.py`

**`src/vectors/`** - Gestion du vector store FAISS
- **R√¥le** : Cr√©ation, sauvegarde, chargement et recherche dans l'index FAISS
- **Fichiers cl√©s** :
  - `vectors.py` : CRUD complet pour FAISS (create, load, search, add, delete, stats)
  - `server.py` : Serveur REPL interactif pour tester les recherches
- **Utilisation** : `make run-vectorstore` (test), `make serve-vectorstore` (REPL)

**`src/chat/`** - Chatbot et prompts
- **R√¥le** : D√©finition de la personnalit√© du chatbot et script CLI de test
- **Fichiers cl√©s** :
  - `ps.md` : Prompt syst√®me "Puls-Events" (persona, directives, exemples)
  - `mistral.py` : Script CLI pour tester le chatbot avec RAG
- **Utilisation** : `make run-chat` (n√©cessite `make run-api` en arri√®re-plan)

**`src/utils/`** - Utilitaires
- **R√¥le** : Scripts d'aide et de maintenance
- **Fichiers cl√©s** :
  - `show_last_update.py` : Affiche les m√©tadonn√©es de derni√®re ex√©cution du pipeline
  - `clean_backups.py` : Nettoie les collections backup MongoDB (interactif/dry-run/force)
- **Utilisation** : `make show-last-update`, `make clean-backups`

**`src/pipeline.py` et `src/update_pipeline.py`** - Orchestration
- **R√¥le** : Pipelines complets end-to-end
- **pipeline.py** : Mode RECREATE (full rebuild) ou UPDATE (incr√©mental)
- **update_pipeline.py** : Pipeline de mise √† jour incr√©mentale avec backup
- **Utilisation** : `make run-embeddings`, `make run-update`

#### **tests/** - Tests et √©valuation
Organisation en 3 cat√©gories :

**Tests unitaires (pytest)**
- `test_api.py` : Tests des endpoints FastAPI (10 tests passants)
- `test_chunks.py` : Tests du chunking
- `test_embeddings.py` : Tests des embeddings
- `test_vectors.py` : Tests du vector store
- `conftest.py` : Fixtures partag√©es (mocks de MongoDB, FAISS, Mistral)
- **Utilisation** : `make test`, `make test-cov`

**√âvaluation RAGAS (qualit√© du RAG)**
- `collect_ragas_data.py` : Collecte les r√©ponses du syst√®me RAG pour √©valuation
- `evaluate_ragas.py` : Calcule les m√©triques RAGAS (faithfulness, relevancy, precision, recall)
- **Utilisation** : `make collect-ragas` puis `make test-ragas`

**Donn√©es de test**
- `ragas_data/ragas_test_questions.json` : 10 questions annot√©es (source)
- `ragas_data/ragas_test_questions_collected.json` : R√©ponses collect√©es (g√©n√©r√©)

#### **data/** - Donn√©es persistantes
- **`data/faiss_index/`** : Index FAISS sauvegard√© sur disque
  - `index.faiss` : Vecteurs (binaire FAISS)
  - `index.pkl` : M√©tadonn√©es et docstore (pickle)
- **Taille** : ~50-100 MB pour 28k √©v√©nements
- **Utilisation** : Charg√© automatiquement au d√©marrage de l'API

#### **rapport/** - Documentation et rapports
- **`technique.md`** : Ce document (rapport technique complet)
- **`Architecture.png`** : Sch√©ma visuel de l'architecture
- **`ragas/ragas_report.html`** : Rapport HTML interactif g√©n√©r√© apr√®s chaque √©valuation RAGAS
  - Dashboard avec m√©triques visuelles
  - Tableau d√©taill√© des scores
  - Recommandations personnalis√©es

#### **database/** - Infrastructure
- **`docker-compose.yml`** : Service MongoDB local pour le d√©veloppement
- **Utilisation** : `cd database && docker-compose up -d`

### Fichiers de configuration racine

**Configuration Python et d√©pendances**
- **`pyproject.toml`** : Configuration du projet (uv, d√©pendances, metadata)
- **`uv.lock`** : Lock file pour reproductibilit√© exacte des versions
- **`.python-version`** : Version Python requise (3.13+)

**Configuration des tests**
- **`pytest.ini`** : Configuration pytest (markers, paths, verbosity)
- **`.coveragerc`** : Configuration de la couverture de code (exclusions, seuils)

**Configuration du linter**
- **`.flake8`** : R√®gles de linting (line length, ignores)

**Variables d'environnement**
- **`.env`** : Variables d'environnement (API keys, configuration) - **non versionn√©**
- **`.env.test`** : Variables sp√©cifiques aux tests RAGAS

**Docker**
- **`Dockerfile`** : Image Docker de l'application FastAPI
- **`docker-compose.yml`** : Orchestration compl√®te (API + MongoDB)
- **`.dockerignore`** : Exclusions du build Docker

**Documentation**
- **`README.md`** : Documentation principale (quick start, installation, utilisation)
- **`CLAUDE.md`** : Instructions pour Claude Code (guide du d√©veloppeur IA)
- **`ARCHITECTURE.md`** : Architecture d√©taill√©e du syst√®me

**Automatisation**
- **`Makefile`** : 40+ commandes pour orchestrer le workflow
  - Pipeline : `make run-all`, `make update`
  - Tests : `make test`, `make test-ragas`
  - API : `make run-api`, `make run-chat`
  - Monitoring : `make show-last-update`, `make show-history`

### Workflow de d√©veloppement typique

**1. Installation initiale**
```bash
make install              # Installe les d√©pendances avec uv
cd database && docker-compose up -d  # D√©marre MongoDB
```

**2. Configuration**
```bash
cp .env.example .env      # Copie le template
# √âditer .env avec les cl√©s API (MISTRAL_API_KEY, OA_API_KEY)
```

**3. Premier build du corpus**
```bash
make run-all              # Pipeline complet (agendas ‚Üí events ‚Üí chunks ‚Üí embeddings)
```

**4. D√©veloppement et tests**
```bash
make run-api              # D√©marre l'API (terminal 1)
make run-chat             # Teste le chatbot (terminal 2)
make test                 # Lance les tests unitaires
make collect-ragas        # Collecte les donn√©es RAGAS
make test-ragas           # √âvalue la qualit√© du RAG
```

**5. Mise √† jour incr√©mentale**
```bash
make update               # Pipeline de mise √† jour (nouveaux √©v√©nements uniquement)
```

**6. Monitoring**
```bash
make show-last-update     # Affiche les m√©tadonn√©es de derni√®re ex√©cution
make show-history         # Affiche l'historique des 5 derni√®res ex√©cutions
```

### Bonnes pratiques du d√©p√¥t

**Versioning**
- `.gitignore` configur√© pour exclure :
  - Variables sensibles (`.env`)
  - Donn√©es g√©n√©r√©es (`data/`, `*.html`, `*_collected.json`)
  - Caches Python (`__pycache__/`, `.pytest_cache/`)
  - Fichiers syst√®me (`.DS_Store`)

**Reproductibilit√©**
- Toutes les d√©pendances sont lock√©es (`uv.lock`)
- Docker Compose pour l'infrastructure
- Variables d'environnement document√©es

**Testabilit√©**
- Tests unitaires avec mocks (pas de d√©pendances externes)
- Tests RAGAS pour la qualit√© end-to-end
- Couverture de code mesur√©e (`make test-cov`)

**Documentation**
- README pour le quick start
- Rapport technique (ce document) pour la vision globale
- Rapports RAGAS HTML pour le suivi qualit√©

10. Annexes (exemples)
Extraits du jeu de test annot√©
Prompt utilis√© (si sp√©cifique)
Extraits de logs ou exemples de r√©ponse JSON
