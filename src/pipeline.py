"""
Pipeline complet pour la cr√©ation de la base vectorielle depuis MongoDB.

Ce module orchestre l'ensemble du processus :
1. Connexion √† MongoDB
2. Chargement et chunking des documents
3. G√©n√©ration des embeddings
4. Cr√©ation de l'index FAISS
5. Sauvegarde et test de recherche
"""

from typing import Optional, Dict, Any
import os
import logging
from dotenv import load_dotenv

from langchain_community.vectorstores import FAISS

from embeddings import get_embeddings_model
from vectors import create_vector_store, save_vector_store, search_similar_documents
from chunks.chunks_document import get_mongodb_connection, process_events_to_chunks

# Configuration du logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def create_vector_store_pipeline(
    save_path: Optional[str] = None,
    mongodb_query: Optional[Dict[str, Any]] = None,
    limit: Optional[int] = None,
    chunk_size: int = 400,
    chunk_overlap: int = 100,
    model_id: Optional[str] = None,
    device: Optional[str] = None,
    batch_size: int = 32,
    verbose: bool = False,
) -> FAISS:
    """
    Pipeline complet: MongoDB ‚Üí chunks ‚Üí embeddings ‚Üí FAISS.

    Args:
        save_path: Chemin pour sauvegarder le vector store (optionnel)
        mongodb_query: Filtre MongoDB pour s√©lectionner les √©v√©nements
        limit: Nombre maximum d'√©v√©nements √† traiter
        chunk_size: Taille des chunks en caract√®res
        chunk_overlap: Chevauchement entre chunks
        model_id: Identifiant du mod√®le d'embeddings
        device: Device √† utiliser ('cuda', 'mps', 'cpu')
        batch_size: Taille des batchs pour les embeddings
        verbose: Si True, affiche des informations de progression

    Returns:
        FAISS: Instance du vector store cr√©√©

    Raises:
        ValueError: Si aucun chunk n'a pu √™tre cr√©√©
    """
    if verbose:
        logger.info("=" * 70)
        logger.info("PIPELINE DE CR√âATION DU VECTOR STORE")
        logger.info("=" * 70)

    # 1. Connexion √† MongoDB
    if verbose:
        logger.info("\n[1/4] Connexion √† MongoDB...")
    client, events_collection = get_mongodb_connection()

    try:
        # 2. Chargement et chunking des documents
        if verbose:
            logger.info("\n[2/4] Chargement et d√©coupage des documents...")
        chunks = process_events_to_chunks(
            events_collection=events_collection,
            query=mongodb_query,
            limit=limit,
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            verbose=verbose,
        )

        if not chunks:
            raise ValueError(
                "Aucun chunk cr√©√©. V√©rifiez que des √©v√©nements existent dans MongoDB."
            )

        # 3. Cr√©ation des embeddings et du vector store
        if verbose:
            logger.info(
                "\n[3/4] G√©n√©ration des embeddings et cr√©ation du vector store..."
            )
            logger.info(f"      Nombre de chunks: {len(chunks)}")
            logger.info(f"      Mod√®le: {model_id or 'intfloat/multilingual-e5-large'}")
            logger.info(f"      Device: {device or 'auto-d√©tect√©'}")
            logger.info(f"      Batch size: {batch_size}")
            logger.info("      Cette √©tape peut prendre plusieurs minutes...")

        embeddings = get_embeddings_model(
            model_id=model_id, device=device, batch_size=batch_size
        )
        vector_store = create_vector_store(chunks, embeddings, verbose=verbose)

        # 4. Sauvegarde du vector store
        if save_path:
            if verbose:
                logger.info("\n[4/4] Sauvegarde du vector store...")
            save_vector_store(vector_store, save_path, verbose=verbose)
        else:
            if verbose:
                logger.info("\n[4/4] Sauvegarde ignor√©e (aucun chemin sp√©cifi√©)")

        if verbose:
            logger.info("\n" + "=" * 70)
            logger.info("‚úì PIPELINE TERMIN√â AVEC SUCC√àS")
            logger.info("=" * 70)

        return vector_store

    finally:
        client.close()
        if verbose:
            logger.info("Connexion MongoDB ferm√©e")


def main():
    """
    Fonction principale pour ex√©cuter le pipeline complet.
    Configuration via variables d'environnement.
    """
    # Chargement des variables d'environnement
    load_dotenv()

    # Configuration
    save_path = os.getenv("FAISS_INDEX_PATH", "data/faiss_index")
    limit = os.getenv("EMBEDDINGS_LIMIT")
    limit = int(limit) if limit else None

    model_id = os.getenv("EMBEDDINGS_MODEL", "intfloat/multilingual-e5-large")
    device = os.getenv("EMBEDDINGS_DEVICE") or None  # None = auto-d√©tection
    batch_size = int(os.getenv("EMBEDDINGS_BATCH_SIZE", "32"))

    try:
        logger.info("D√©marrage du pipeline de cr√©ation du vector store...")

        # Ex√©cution du pipeline complet
        vector_store = create_vector_store_pipeline(
            save_path=save_path,
            limit=limit,
            model_id=model_id,
            device=device,
            batch_size=batch_size,
            verbose=True,
        )

        # Test de recherche (optionnel)
        test_query = os.getenv("TEST_QUERY")
        if test_query:
            logger.info(f"\n{'='*70}")
            logger.info("üîç TEST DE RECHERCHE S√âMANTIQUE")
            logger.info(f"{'='*70}")
            logger.info(f"Requ√™te: '{test_query}'")

            results = search_similar_documents(
                vector_store, test_query, k=5, verbose=True
            )

            logger.info(f"\n{'='*70}")
            logger.info("üìä R√âSULTATS D√âTAILL√âS")
            logger.info("=" * 70)

            for i, (doc, score) in enumerate(results, 1):
                logger.info(f"\n--- R√©sultat {i} (Score: {score:.4f}) ---")
                logger.info(f"Titre: {doc.metadata.get('title', 'N/A')}")
                logger.info(f"Lieu: {doc.metadata.get('locationName', 'N/A')}")
                logger.info(f"Date: {doc.metadata.get('dateRange', 'N/A')}")
                logger.info(f"R√©gion: {doc.metadata.get('region', 'N/A')}")
                logger.info(f"\nExtrait: {doc.page_content[:300]}...")
                logger.info("-" * 70)

        logger.info("\n‚úì Programme termin√© avec succ√®s")

    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'ex√©cution du pipeline: {e}", exc_info=True)
        raise


if __name__ == "__main__":
    main()
